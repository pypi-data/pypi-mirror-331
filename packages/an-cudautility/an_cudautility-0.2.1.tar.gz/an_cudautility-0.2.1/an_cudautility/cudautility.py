# -*- coding: utf-8 -*-
"""CUDU_20250305_00.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eDafNQrp0Acl5Fzr5b87Q7MLFJrOhoOL

# CudaUtility
 Cudaサポートユーティリティ


```
2025/02/24 0.1.0 完成
2025/02/27 0.2.0 check_gpu追加。
2025/03/05 0.2.1 version_symbol改良。11.8.0というバージョン番号にも対応
```

# CudaUtility

## 1. GDrive接続
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 2. モジュール定義"""

# @title a. CudaUtility 定義
import os
import torch

class CudaUtility:
    def __init__(self):
        pass
        # GPUの状態や情報を格納するメンバ変数
        self.gpu_available = False
        self.gpu_info = None

    def check_status( self ):
        print( "1️⃣ CUDA関連パッケージインストール状況" )
        get_ipython().system("dpkg -l | grep cuda")
        get_ipython().system("dpkg -l | grep libcudnn")

        print( "2️⃣ CUDAファイル残存状況確認" )
        get_ipython().system("ls -l /usr/local | grep cuda")
        get_ipython().system("ls -l /usr/lib | grep cuda")
        get_ipython().system("ls -l /usr/lib64 | grep cuda")

        print( "3️⃣ 環境変数の影響を確認" )
        get_ipython().system("echo $PATH")
        get_ipython().system("echo $LD_LIBRARY_PATH")

    # 旧称 get_cuda_version_symbol
    def version_symbol(self, cuda_version: str) -> str:
        """
        CUDAのバージョン番号 (例: "11.8", "11.8.0", "12.4") を
        CUDAのシンボル (例: "CU118", "CU124") に変換する。

        入力が "11.8.0" のように3部構成の場合でも、最初の2部を使ってシンボルを生成します。

        :param cuda_version: CUDAのバージョン番号 (例: "11.8", "11.8.0", "12.4")
        :return: 変換されたシンボル (例: "CU118", "CU124")
        """
        parts = cuda_version.split('.')
        if len(parts) < 2:
            raise ValueError(f"Invalid CUDA version format: {cuda_version}")
        major = parts[0]
        minor = parts[1]
        return f"CU{major}{minor}"


    def check_gpu(self):
        """
        GPUが有効ならTrue、無効ならFalseを返す。
        まずtorch.cuda.is_available()で確認し、Falseの場合は /proc/driver/nvidia/version をチェックする。
        """
        try:
            # PyTorchでGPUが利用可能かどうかチェック
            available = torch.cuda.is_available()
        except Exception as e:
            available = False

        if available:
            self.gpu_available = True
            self.gpu_info = "torch.cuda.is_available() returned True"
            return True
        else:
            # torchがFalseを返した場合、低レベルな方法として /proc/driver/nvidia/version を確認
            if os.path.exists("/proc/driver/nvidia/version"):
                try:
                    with open("/proc/driver/nvidia/version", "r") as f:
                        version_info = f.read().strip()
                    self.gpu_available = True
                    self.gpu_info = version_info
                    return True
                except Exception as e:
                    self.gpu_available = False
                    self.gpu_info = f"Error reading /proc/driver/nvidia/version: {e}"
                    return False
            else:
                self.gpu_available = False
                self.gpu_info = "GPU is not available (torch reports False and /proc/driver/nvidia/version not found)"
                return False

"""## 3. 実行"""

# @title a. 実行
if __name__ == "__main__":
    cudautility = CudaUtility()
    cudautility.check_status()
    print(cudautility.version_symbol("11.8"))
    print(cudautility.version_symbol("11.8.0"))
    print(cudautility.version_symbol("12.4"))

# 使用例
if __name__ == "__main__":
    cudau = CudaUtility()
    if cudau.check_gpu():
        print("GPUは有効です。")
        print("GPU情報:")
        print(cudau.gpu_info)
    else:
        print("GPUは無効です。")
        print("詳細:")
        print(cudau.gpu_info)