$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
environment_variables:
  PROMPTFLOW_SERVING_ENGINE: fastapi
  PF_DISABLE_TRACING: "false"
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${semantic_kernel_chat.output}
    is_chat_output: true
nodes:
- name: semantic_kernel_chat
  type: custom_llm
  source:
    type: package_with_prompt
    tool: promptflow_tool_semantic_kernel.tools.semantic_kernel_tool.semantic_kernel_chat
    path: semantic_kernel_chat.jinja2
  inputs:
    connection: open_ai_connection
    deployment_name: gpt-4o
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    plugins:
    - name: lights
      class: LightsPlugin
      module: promptflow_tool_semantic_kernel.tools.lights_plugin
