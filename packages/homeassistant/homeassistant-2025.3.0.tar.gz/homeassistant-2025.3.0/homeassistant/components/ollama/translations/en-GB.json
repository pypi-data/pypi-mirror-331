{
    "config": {
        "abort": {
            "download_failed": "Model downloading failed"
        }
    },
    "options": {
        "step": {
            "init": {
                "data": {
                    "keep_alive": "Keep alive",
                    "llm_hass_api": "Control Home Assistant",
                    "num_ctx": "Context window size"
                },
                "data_description": {
                    "keep_alive": "Duration in seconds for Ollama to keep model in memory. -1 = indefinite, 0 = never.",
                    "num_ctx": "Maximum number of text tokens the model can process. Lower to reduce Ollama RAM, or increase for a large number of exposed entities.",
                    "prompt": "Instruct how the LLM should respond. This can be a template."
                }
            }
        }
    }
}