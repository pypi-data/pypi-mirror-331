{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d614809e-bad2-4b28-9e05-8585f1dbb106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogen\n",
      "  Downloading autogen-0.7.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting proton_driver\n",
      "  Downloading proton_driver-0.2.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.9 kB)\n",
      "Collecting pyautogen==0.7.5 (from autogen)\n",
      "  Downloading pyautogen-0.7.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting asyncer==0.0.8 (from pyautogen==0.7.5->autogen)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting diskcache (from pyautogen==0.7.5->autogen)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docker (from pyautogen==0.7.5->autogen)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fast-depends<3,>=2.4.12 (from pyautogen==0.7.5->autogen)\n",
      "  Downloading fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (1.24.4)\n",
      "Collecting openai>=1.58 (from pyautogen==0.7.5->autogen)\n",
      "  Downloading openai-1.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (23.2)\n",
      "Collecting pydantic<3,>=2.6.1 (from pyautogen==0.7.5->autogen)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting python-dotenv (from pyautogen==0.7.5->autogen)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting termcolor (from pyautogen==0.7.5->autogen)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tiktoken (from pyautogen==0.7.5->autogen)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n",
      "Collecting websockets<15,>=14 (from pyautogen==0.7.5->autogen)\n",
      "  Downloading websockets-14.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from asyncer==0.0.8->pyautogen==0.7.5->autogen) (4.0.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from proton_driver) (2023.3.post1)\n",
      "Collecting tzlocal (from proton_driver)\n",
      "  Downloading tzlocal-5.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.7.5->autogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.7.5->autogen) (2.0.7)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->pyautogen==0.7.5->autogen)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.5->autogen) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker->pyautogen==0.7.5->autogen) (3.3.0)\n",
      "Downloading autogen-0.7.5-py3-none-any.whl (12 kB)\n",
      "Downloading pyautogen-0.7.5-py3-none-any.whl (606 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Downloading proton_driver-0.2.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (979 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.4/979.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.3-py3-none-any.whl (17 kB)\n",
      "Downloading fast_depends-2.4.12-py3-none-any.whl (17 kB)\n",
      "Downloading openai-1.64.0-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-14.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.5/335.5 kB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.1/792.1 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: websockets, tzlocal, typing-extensions, termcolor, regex, python-dotenv, jiter, h11, distro, diskcache, annotated-types, tiktoken, pydantic-core, proton_driver, httpcore, docker, asyncer, pydantic, httpx, openai, fast-depends, pyautogen, autogen\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "Successfully installed annotated-types-0.7.0 asyncer-0.0.8 autogen-0.7.5 diskcache-5.6.3 distro-1.9.0 docker-7.1.0 fast-depends-2.4.12 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.64.0 proton_driver-0.2.13 pyautogen-0.7.5 pydantic-2.10.6 pydantic-core-2.27.2 python-dotenv-1.0.1 regex-2024.11.6 termcolor-2.5.0 tiktoken-0.9.0 typing-extensions-4.12.2 tzlocal-5.3 websockets-14.2\n"
     ]
    }
   ],
   "source": [
    "! pip install autogen proton_driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad799c60-462a-4966-bdea-38efd17f1aa4",
   "metadata": {},
   "source": [
    "### Define Timeplus Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef0cc53-f4fc-44cb-a1c6-b6f8d240b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from proton_driver import client\n",
    "\n",
    "timeplus_host = os.getenv(\"TIMEPLUS_HOST\") or \"localhost\"\n",
    "timeplus_user = os.getenv(\"TIMEPLUS_USER\") or \"proton\"\n",
    "timeplus_password = os.getenv(\"TIMEPLUS_PASSWORD\") or \"timeplus@t+\"\n",
    "\n",
    "class Tools:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = client.Client(host=timeplus_host, port=8463, user=timeplus_user,password=timeplus_password)\n",
    "\n",
    "    def list_table(self, *args):\n",
    "        result = []\n",
    "        rows = self.client.execute_iter(\"SHOW STREAMS\")\n",
    "        for row in rows:\n",
    "            result.append(row[0])\n",
    "        return result\n",
    "    \n",
    "    def describe_table(self, *args):\n",
    "        name = args[0]\n",
    "        result = []\n",
    "        rows = self.client.execute_iter(f\"DESCRIBE {name.strip()}\")\n",
    "        for row in rows:\n",
    "            col = {}\n",
    "            col[\"name\"] =  row[0]\n",
    "            col[\"type\"] =  row[1]\n",
    "            result.append(col)\n",
    "        return result\n",
    "\n",
    "    def run(self, tool_name, *args):\n",
    "        result = getattr(self, tool_name)(*args)\n",
    "        return result\n",
    "\n",
    "    def list(self):\n",
    "        return [\"list_table\", \"describe_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5d1ad4-fd33-471d-b441-65b0570f2984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'raw', 'type': 'string'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = Tools()\n",
    "\n",
    "tool.list_table()\n",
    "\n",
    "tool.describe_table('kafka_cdc_postgres_customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b4ffc1-1b88-43b9-917e-d208ef8ee680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_table() -> Annotated[str, \"The name of tables in the system\"]:\n",
    "    return tool.list_table()\n",
    "\n",
    "def describe_table(name: Annotated[str, \"The name of the table\"]) -> Annotated[str, \"schema definition of the table\"]:\n",
    "    return tool.describe_table(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d0eb08-0745-46b8-868b-123670437679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "\n",
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, register_function\n",
    "from autogen.agentchat.contrib.capabilities import teachability\n",
    "from autogen.cache import Cache\n",
    "from autogen.coding import DockerCommandLineCodeExecutor, LocalCommandLineCodeExecutor\n",
    "\n",
    "config_list = [\n",
    "    {\"model\": \"gpt-4o\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48cfc840-294f-428f-a841-c1544b4ed881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this ReAct prompt is adapted from Langchain's ReAct agent: https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py#L79\n",
    "ReAct_prompt = \"\"\"\n",
    "You are a asistent help generating SQL based on input questions. \n",
    "Please stop when you have the SQL, no need to execute the SQL\n",
    "To generate SQL, here are rules:\n",
    "* the grammar follows ClickHouse style\n",
    "* all datatypes MUST be in lowercase, such uint32\n",
    "* all keywords MUST be in lowercase, such as nullable\n",
    "* for normal query, add table() function to the table name, for example select count(*) from table(table_name)\n",
    "* for real time query, where continously return new result to the user, append a time range, for example\n",
    "  select count(*) from table_name where _tp_time > now() -1h\n",
    "  which will return the number of event received in the past 1 hour\n",
    "\n",
    "You have access to tools provided.\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this process can repeat multiple times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "# Define the ReAct prompt message. Assuming a \"question\" field is present in the context\n",
    "\n",
    "\n",
    "def react_prompt_message(sender, recipient, context):\n",
    "    return ReAct_prompt.format(input=context[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0174d79d-3089-443d-9b04-d779827a9204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "You are a asistent help generating SQL based on input questions. \n",
      "Please stop when you have the SQL, no need to execute the SQL\n",
      "To generate SQL, here are rules:\n",
      "* the grammar follows ClickHouse style\n",
      "* all datatypes MUST be in lowercase, such uint32\n",
      "* all keywords MUST be in lowercase, such as nullable\n",
      "* for normal query, add table() function to the table name, for example select count(*) from table(table_name)\n",
      "* for real time query, where continously return new result to the user, append a time range, for example\n",
      "  select count(*) from table_name where _tp_time > now() -1h\n",
      "  which will return the number of event received in the past 1 hour\n",
      "\n",
      "You have access to tools provided.\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this process can repeat multiple times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "Question: how many customer are there in the past 1 day in real time\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_Gqk37j9Ba25YW1TLRKFCozxD): list_table *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION list_table...\n",
      "Call ID: call_Gqk37j9Ba25YW1TLRKFCozxD\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_Gqk37j9Ba25YW1TLRKFCozxD) *****\u001b[0m\n",
      "['kafka_cdc_mongo_unstructure', 'kafka_cdc_postgres_credit_history', 'kafka_cdc_postgres_customers', 'kafka_test_cdc_mongo_raw', 'mongo_cdc_target_payload', 'mongo_payload', 'v_mongo_cdc_after_payload']\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_PQ8pJPW87wvcbCDhVxYnFWOw): describe_table *****\u001b[0m\n",
      "Arguments: \n",
      "{\"name\":\"kafka_cdc_postgres_customers\"}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION describe_table...\n",
      "Call ID: call_PQ8pJPW87wvcbCDhVxYnFWOw\n",
      "Input arguments: {'name': 'kafka_cdc_postgres_customers'}\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_PQ8pJPW87wvcbCDhVxYnFWOw) *****\u001b[0m\n",
      "[{'name': 'raw', 'type': 'string'}]\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "SELECT count(*) FROM kafka_cdc_postgres_customers WHERE _tp_time > now() - 1d; \n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " the final answer is SELECT count(*) FROM kafka_cdc_postgres_customers WHERE _tp_time > now() - 1d; \n",
      "TERMINATE \n"
     ]
    }
   ],
   "source": [
    "# Setting up code executor.\n",
    "os.makedirs(\"coding\", exist_ok=True)\n",
    "# Use docker executor for running code in a container if you have docker installed.\n",
    "# code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "code_executor = LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    ##code_execution_config={\"executor\": code_executor},\n",
    ")\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=(\n",
    "        \"Only use the tools you have been provided with.\"\n",
    "        \"You are a SQL generator. Your task is to generate SQL queries and nothing else. \"\n",
    "        \"Do NOT execute SQL or ask for execution. Once the SQL is generated, respond with TERMINATE.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n",
    ")\n",
    "\n",
    "# Register the timeplus tool.\n",
    "register_function(\n",
    "    list_table,\n",
    "    caller=assistant,\n",
    "    executor=user_proxy,\n",
    "    name=\"list_table\",\n",
    "    description=\"list available tables in the system\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    describe_table,\n",
    "    caller=assistant,\n",
    "    executor=user_proxy,\n",
    "    name=\"describe_table\",\n",
    "    description=\"return the schema of the table\",\n",
    ")\n",
    "\n",
    "# Cache LLM responses. To get different responses, change the cache_seed value.\n",
    "with Cache.disk(cache_seed=43) as cache:\n",
    "    user_proxy.initiate_chat(\n",
    "        assistant,\n",
    "        message=react_prompt_message,\n",
    "        question=\"how many customer are there in the past 1 day in real time\",\n",
    "        cache=cache,\n",
    "    )\n",
    "\n",
    "    print(f\" the final answer is { user_proxy.last_message()['content'] } \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
