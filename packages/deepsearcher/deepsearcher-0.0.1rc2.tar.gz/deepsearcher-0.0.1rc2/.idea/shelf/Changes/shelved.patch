Index: deepsearcher/configuration.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from typing import Literal\n\nfrom deepsearcher.embedding.base import BaseEmbedding\nfrom deepsearcher.llm.base import BaseLLM\nfrom deepsearcher.loader.file_loader.base import BaseLoader\nfrom deepsearcher.loader.web_crawler.base import BaseCrawler\nfrom deepsearcher.vector_db.base import BaseVectorDB\n\nFeatureType = Literal[\"llm\", \"embedding\", \"file_loader\", \"web_crawler\", \"vector_db\"]\n\nclass Configuration:\n    def __init__(self):\n        # Initialize default configurations\n        self.provide_settings = {\n            \"llm\": {\n                \"provider\": \"OpenAI\",#\"TogetherAI\",\n                \"config\": {\n                    \"model\": \"gpt-4o-mini\" #\"gpt-4o\"#\"deepseek-ai/DeepSeek-V3\"\n                }\n            },\n            \"embedding\": {\n                \"provider\": \"MilvusEmbedding\",\n                \"config\": {\n                    \"model_name\": \"default\"\n                }\n            },\n            \"file_loader\": {\n                \"provider\": \"PDFLoader\",\n                \"config\": {}\n            },\n            \"web_crawler\": {\n                \"provider\": \"FireCrawlCrawler\",\n                \"config\": {}\n            },\n            \"vector_db\": {\n                \"provider\": \"Milvus\",\n                \"config\": {\n                    \"uri\": \"./milvus.db\"\n                }\n            }\n        }\n        self.query_settings = {\n            \"max_iter\": 3\n        }\n\n    def set_provider_config(self, feature: FeatureType, provider: str, provider_configs: dict):\n        \"\"\"\n        Set the provider and its configurations for a given feature.\n\n        :param feature: The feature to configure (e.g., 'llm', 'file_loader', 'web_crawler').\n        :param provider: The provider name (e.g., 'openai', 'deepseek').\n        :param provider_configs: A dictionary with configurations specific to the provider.\n        \"\"\"\n        if feature not in self.provide_settings:\n            raise ValueError(f\"Unsupported feature: {feature}\")\n\n        self.provide_settings[feature][\"provider\"] = provider\n        self.provide_settings[feature][\"config\"] = provider_configs\n\n\n    def get_provider_config(self, feature: FeatureType):\n        \"\"\"\n        Get the current provider and configuration for a given feature.\n\n        :param feature: The feature to retrieve (e.g., 'llm', 'file_loader', 'web_crawler').\n        :return: A dictionary with provider and its configurations.\n        \"\"\"\n        if feature not in self.provide_settings:\n            raise ValueError(f\"Unsupported feature: {feature}\")\n\n        return self.provide_settings[feature]\n\nclass ModuleFactory:\n    def __init__(self, config: Configuration):\n        self.config = config\n    \n    def _create_module_instance(self, feature: FeatureType, module_name: str):\n        # e.g.\n        # feature = \"file_loader\"\n        # module_name = \"deepsearcher.loader.file_loader\"\n        class_name = self.config.provide_settings[feature][\"provider\"]\n        module = __import__(module_name, fromlist=[class_name])\n        class_ = getattr(module, class_name)\n        return class_(**self.config.provide_settings[feature][\"config\"])\n    \n    def create_llm(self) -> BaseLLM:\n        return self._create_module_instance(\"llm\", \"deepsearcher.llm\")\n    \n    def create_embedding(self) -> BaseEmbedding:\n        return self._create_module_instance(\"embedding\", \"deepsearcher.embedding\")\n    \n    def create_file_loader(self) -> BaseLoader:\n        return self._create_module_instance(\"file_loader\", \"deepsearcher.loader.file_loader\")\n    \n    def create_web_crawler(self) -> BaseCrawler:\n        return self._create_module_instance(\"web_crawler\", \"deepsearcher.loader.web_crawler\")\n    \n    def create_vector_db(self) -> BaseVectorDB:\n        return self._create_module_instance(\"vector_db\", \"deepsearcher.vector_db\")\n    \n\nconfig = Configuration()\n\nmodule_factory: ModuleFactory = None\nllm: BaseLLM = None\nembedding_model: BaseEmbedding = None\nfile_loader: BaseLoader = None\nvector_db: BaseVectorDB = None\nweb_crawler: BaseCrawler = None\n\n\ndef init_config(config: Configuration):\n    global module_factory, llm, embedding_model, file_loader, vector_db, web_crawler\n    module_factory = ModuleFactory(config)\n    llm = module_factory.create_llm()\n    embedding_model = module_factory.create_embedding()\n    file_loader = module_factory.create_file_loader()\n    web_crawler = module_factory.create_web_crawler()\n    vector_db = module_factory.create_vector_db()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/deepsearcher/configuration.py b/deepsearcher/configuration.py
--- a/deepsearcher/configuration.py	(revision b36055d03a36fbc5791807be140171e4a58823ec)
+++ b/deepsearcher/configuration.py	(date 1739168435863)
@@ -35,7 +35,9 @@
             "vector_db": {
                 "provider": "Milvus",
                 "config": {
-                    "uri": "./milvus.db"
+                    # "uri": "./milvus.db"  #TODO
+                    "uri": "http://10.100.30.11:19530",  #TODO
+                    "db": "deeprag_test"
                 }
             }
         }
