# generated by datamodel-codegen:
#   filename:  application.json
#   timestamp: 2025-02-26T17:51:02+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Literal, Optional, Union

from truefoundry.pydantic_v1 import (
    BaseModel,
    Field,
    PositiveFloat,
    PositiveInt,
    confloat,
    conint,
    constr,
)


class AMQPInputConfig(BaseModel):
    """
    +docs=Describes the configuration for the input AMQP worker
    +label=AMQP
    """

    type: Literal["amqp"] = Field(..., description="+value=amqp")
    url: constr(
        regex=r"^(amqp|amqps?)://(?:[^:@]+(?::[^:@]+)?@)?([^/?]+)(?:/([^?]+))?/?([^?]+)?(?:\?(.*))?$"
    ) = Field(
        ...,
        description="+label=Queue URL\n+usage=AMQP Queue URL of Subscriber\n+sort=1",
    )
    queue_name: str = Field(
        ..., description="+label=Queue Name\n+usage=AMQP Queue Name\n+sort=2"
    )
    wait_time_seconds: conint(ge=1) = Field(
        5, description="+label=Wait Time Seconds\n+usage=Wait timeout for long polling."
    )


class AMQPMetricConfig(BaseModel):
    type: Literal["amqp"] = Field(..., description="+value=amqp")
    queue_length: conint(ge=1) = Field(
        ...,
        description="+label=Queue Length\n+usage=Upper limit of the number of backlog messages the auto-scaler will try to maintain per replica. If you set this number to 10 and have 30 messages in the stream and one replica, the auto-scaler will scale the number of replicas to 3.",
    )


class AMQPOutputConfig(BaseModel):
    """
    +docs=Describes the configuration for the output AMQP worker
    +label=AMQP
    """

    type: Literal["amqp"] = Field(..., description="+value=amqp")
    url: constr(
        regex=r"^(amqp|amqps?)://(?:[^:@]+(?::[^:@]+)?@)?([^/?]+)(?:/([^?]+))?/?([^?]+)?(?:\?(.*))?$"
    ) = Field(
        ..., description="+label=Queue URL\n+usage=AMQP Queue URL of Publisher\n+sort=1"
    )
    routing_key: str = Field(
        ...,
        description="+label=Routing Key\n+usage=AMQP Routing Key to publish to.\n+sort=2",
    )
    exchange_name: Optional[str] = Field(
        None, description="+label=Exchange Name\n+usage=AMQP Exchange Name\n+sort=3"
    )


class AWSAccessKeyAuth(BaseModel):
    aws_access_key_id: str = Field(
        ..., description="+label=AWS Access Key ID\n+usage=AWS Access Key ID\n+sort=1"
    )
    aws_secret_access_key: str = Field(
        ...,
        description="+label=AWS Secret Access Key\n+usage=AWS Secret Access Key for the user to authenticate with\n+sort=2",
    )
    aws_session_token: Optional[str] = Field(
        None,
        description="+label=AWS Session Token\n+usage=AWS Session Token, only required when using temporary credentials\n+sort=3",
    )


class AWSInferentia(BaseModel):
    type: Literal["aws_inferentia"] = Field(..., description="+value=aws_inferentia")
    name: Optional[str] = Field(
        None,
        description="+label=Inferentia accelerator name\n+usage=Name of the AWS Inferentia Accccelerator. One of [INF1, INF2].\nThis field is required for Node Selector and can be ignored in Nodepool Selector.",
    )
    count: conint(ge=1, le=16) = Field(
        ...,
        description="+label=Count\n+usage=Count of Inferentia accelerator chips to provide to the application",
    )


class ArtifactsCacheVolume(BaseModel):
    """
    +docs=Describes the volume that will be used to cache the models
    +label=Artifacts Cache Volume
    """

    storage_class: str = Field(
        ...,
        description="+label=Storage Class\n+usage=Storage class of the Volume where artifacts will be cached",
    )
    cache_size: conint(ge=1, le=1000) = Field(
        200,
        description="+label=Cache Size (GB)\n+usage=Size of the Volume (in GB) where artifacts will be cached. Should be greater than twice the size of artifacts getting cached",
    )


class AsyncProcessorSidecar(BaseModel):
    destination_url: str = Field(
        ...,
        description="+label=Destination URL\n+usage=URL for the processor to invoke",
    )
    request_timeout: conint(ge=1) = Field(
        10,
        description="+label=Request Timeout Seconds\n+usage=Timeout for the invoke request in seconds",
    )
    sidecar_image: Optional[str] = Field(
        None,
        description="+label=Sidecar Image\n+usage=Image for the processor sidecar (This field will be deprecated in the future)",
    )


class Autoshutdown(BaseModel):
    wait_time: conint(ge=0) = Field(
        300,
        description="+label=Wait Time\n+usage=The period to wait after the last received request before scaling the replicas to 0",
    )


class BaseAutoscaling(BaseModel):
    min_replicas: conint(ge=0) = Field(
        1,
        description="+label=Minimum replicas\n+usage=Minimum number of replicas to keep available\n+sort=1",
    )
    max_replicas: conint(ge=1, le=500) = Field(
        ...,
        description="+label=Maximum replicas\n+usage=Maximum number of replicas allowed for the component.\n+sort=2",
    )
    polling_interval: conint(ge=0) = Field(
        30,
        description="+label=Polling Interval\n+usage=This is the interval to check each trigger on.",
    )


class BasicAuthCreds(BaseModel):
    """
    +label=Username and password
    """

    type: Literal["basic_auth"] = Field(..., description="+value=basic_auth")
    username: str = Field(
        ...,
        description="+label=Username for service auth\n+message=Username for the user to authenticate with\n+sort=1",
    )
    password: str = Field(
        ...,
        description="+label=Password for service auth\n+message=Password for the user to authenticate with\n+sort=2",
    )


class BlueGreen(BaseModel):
    """
    +docs=This strategy brings up the new release completely before switching the complete load to the new release.
    This minimizes the time that two versions are serving traffic at the same time.
    +label=Blue Green strategy
    """

    type: Literal["blue_green"] = Field(..., description="+value=blue_green")
    enable_auto_promotion: bool = Field(
        False,
        description="+docs=Promote the new release to handle the complete traffic. A manual promotion would be needed if this is disabled\n+label=Auto-promotion",
    )
    auto_promotion_seconds: conint(ge=0) = Field(
        30,
        description="+docs=Promote the new release to handle the complete traffic after waiting for these many seconds\n+label=Auto-promotion seconds",
    )


class CPUUtilizationMetric(BaseModel):
    type: Literal["cpu_utilization"] = Field(..., description="+value=cpu_utilization")
    value: conint(ge=1, le=100) = Field(
        ...,
        description="+label=CPU utilization %\n+usage=Percentage of cpu request averaged over all replicas which the autoscaler should try to maintain",
    )


class CanaryStep(BaseModel):
    weight_percentage: conint(ge=0, le=100) = Field(
        ...,
        description="+docs=Percentage of total traffic to be shifted to the canary release.\nThe rest will continue to go to the existing deployment\n+label=Canary weight percentage\n+unit=%\n+placeholder=Weight",
    )
    pause_duration: conint(ge=0) = Field(
        30,
        description="+docs=Duration for which to pause the release. The release process will wait for these seconds before proceeding to the next step.\nIf this is not set, the step will pause indefinitely on this step\n+label=Pause duration\n+unit=seconds\n+placeholder=Duration",
    )


class CronMetric(BaseModel):
    type: Literal["cron"] = Field(..., description="+value=cron")
    desired_replicas: Optional[conint(ge=1)] = Field(
        None,
        description="+label=Desired Replicas\n+usage=Desired number of replicas during the given interval. Default value is max_replicas.",
    )
    start: str = Field(
        ...,
        description="+label=Start Schedule\n+docs=Cron expression indicating the start of the cron schedule.\n+usage=Cron expression indicating the start of the cron schedule.\n```\n* * * * *\n| | | | |\n| | | | |___ day of week (0-6) (Sunday is 0)\n| | | |_____ month (1-12)\n| | |_______ day of month (1-31)\n| |_________ hour (0-23)\n|___________ minute (0-59)\n```",
    )
    end: str = Field(
        ...,
        description="+label=End Schedule\n+docs=Cron expression indicating the end of the cron schedule.\n+usage=Cron expression indicating the end of the cron schedule.\n```\n* * * * *\n| | | | |\n| | | | |___ day of week (0-6) (Sunday is 0)\n| | | |_____ month (1-12)\n| | |_______ day of month (1-31)\n| |_________ hour (0-23)\n|___________ minute (0-59)\n```",
    )
    timezone: str = Field(
        "UTC",
        description='+usage=Timezone against which the cron schedule will be calculated, e.g. "Asia/Tokyo". Default is machine\'s local time.\nhttps://docs.truefoundry.com/docs/list-of-supported-timezones',
    )


class DockerFileBuild(BaseModel):
    """
    +docs=Describes that we are using a dockerfile to build our image
    +label=Docker File (I already have Docker File)
    +icon=fa-brands fa-docker:#0db7ed
    """

    type: Literal["dockerfile"] = Field(..., description="+value=dockerfile")
    dockerfile_path: str = Field(
        "./Dockerfile",
        description="+label=Path to Dockerfile\n+usage=The file path of the Dockerfile relative to project root path.",
    )
    build_context_path: str = Field(
        "./",
        description="+label=Path to build context\n+usage=Build context path for the Dockerfile relative to project root path.",
    )
    command: Optional[Union[str, List[str]]] = Field(
        None,
        description="+label=Command Override\n+usage=Override the command to run when the container starts\nWhen deploying a Job, the command can be templatized by defining `params` and referencing them in command\nE.g. `python main.py --learning_rate {{learning_rate}}`",
    )
    build_args: Optional[Dict[str, str]] = Field(
        None, description="+label=Build arguments to pass to docker build"
    )


class DynamicVolumeConfig(BaseModel):
    """
    +label=Dynamic Volume Config
    """

    type: Literal["dynamic"] = Field(
        ...,
        description="+label=Volume Type\n+value=dynamic\n+usage=Volume Type for the volume.",
    )
    storage_class: str = Field(
        ...,
        description="+label=Storage Class Name\n+usage=Name of the storage class to be used for the volume.",
    )
    size: conint(ge=1, le=64000) = Field(
        ..., description="+label=Size\n+unit=Gi\n+usage=Size of volume in Gi"
    )


class Endpoint(BaseModel):
    host: constr(
        regex=r"^((([a-zA-Z0-9\-]{1,63}\.)([a-zA-Z0-9\-]{1,63}\.)*([A-Za-z]{1,63}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))$"
    ) = Field(
        ...,
        description="+usage=Host e.g. ai.example.com, app.truefoundry.com\n+message=Upto 253 characters, each part of host should be at most 63 characters long, can contain alphabets, digits and hypen, must begin and end with an alphanumeric characters. Parts must be separated by periods (.)",
    )
    path: Optional[
        constr(regex=r"^(/([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-_\.]*[a-zA-Z0-9]))*/$")
    ] = Field(
        None,
        description="+usage=Path e.g. /v1/api/ml/, /v2/docs/\n+message=Should begin and end with a forward slash (/). Each part can can contain alphabets, digits and hypen, must begin and end with an alphanumeric characters. Parts should be separated by forward slashes (/)",
    )


class FlyteLaunchPlanID(BaseModel):
    resourceType: Literal["LAUNCH_PLAN"]
    name: str


class FlyteTaskID(BaseModel):
    resourceType: Literal["TASK"]
    name: str


class FlyteWorkflowID(BaseModel):
    resourceType: Literal["WORKFLOW"]
    name: str


class FlyteWorkflowTemplate(BaseModel):
    id: FlyteWorkflowID


class GcpTPU(BaseModel):
    type: Literal["gcp_tpu"] = Field(..., description="+value=gcp_tpu")
    name: constr(regex=r"^tpu-[a-z\d\-]+$") = Field(
        ...,
        description="+label=TPU Type name\n+usage=Name of the TPU Type. One of\n  - `tpu-v4-podslice` (TPU v4, ct4p)\n  - `tpu-v5-lite-device` (TPU v5e, ct5l)\n  - `tpu-v5-lite-podslice`  (TPU v5e, ct5lp)\n  - `tpu-v5p-slice` (TPU v5p, ct5p)",
    )
    topology: constr(regex=r"^\d+x\d+(x\d+)?$") = Field(
        ...,
        description="+label=Slice Topology\n+usage=Topology of the TPU slices. Currently only single-host topology is supported.\n Please refer to [TPUs on GKE docs](https://cloud.google.com/kubernetes-engine/docs/concepts/tpus#plan-tpu-configuration)\n Allowed Values:\n   - `2x2x1` for `tpu-v4-podslice`\n   - One of `1x1`, `2x2`, `2x4` for `tpu-v5-lite-device` and `tpu-v5-lite-podslice`\n   - `2x2x1` for `tpu-v5p-slice`",
    )


class GitHelmRepo(BaseModel):
    type: Literal["git-helm-repo"] = Field(..., description="+value=git-helm-repo")
    repo_url: constr(
        regex=r"^(((https?|wss):\/\/)?(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}(?:[-a-zA-Z0-9()@:%_\+.~#?&\/=]*))$"
    ) = Field(
        ...,
        description="TODO: Check this regex and add guidelines\n+label=Git repository URL\n+sort=1\n+message=Needs to be a valid URL.",
    )
    revision: str = Field(
        ...,
        description="+label=Revision\n+sort=2\n+usage=Branch/Commit SHA/Tag of the git repo.",
    )
    path: str = Field(
        ..., description="+label=Path\n+sort=3\n+usage=Path to the chart."
    )
    value_files: Optional[List[str]] = Field(
        None,
        description="+label=Value files\n+sort=3\n+usage=Helm values files for overriding values in the helm chart.\nThe path is relative to the Path directory defined above",
    )


class GitSource(BaseModel):
    """
    +docs=Describes that we are using code stored in a git repository to build our image
    +label=Git Source
    +icon=fa-solid fa-code-branch:black
    +sort=300
    """

    type: Literal["git"] = Field(..., description="+value=git")
    repo_url: constr(
        regex=r"^(http(s?)://)(github\.com|(.+@)*bitbucket\.org|gitlab\.com|(.*)@dev.azure.com).*$"
    ) = Field(
        ...,
        description="+label=Repo URL\n+usage=The repository URL.\n+sort=1\n+message=Needs to be a valid Github, Bitbucket, Azure Repos or Gitlab link",
    )
    ref: str = Field(
        ..., description="+label=Commit SHA\n+usage=The commit SHA.\n+sort=2"
    )
    branch_name: Optional[str] = Field(
        None,
        description="+label=Branch Name\n+usage=Selecting branch will select latest commit SHA of the branch.\n+sort=3",
    )


class HelmRepo(BaseModel):
    type: Literal["helm-repo"] = Field(..., description="+value=helm-repo")
    repo_url: constr(
        regex=r"^(((https?|wss):\/\/)?(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}(?:[-a-zA-Z0-9()@:%_\+.~#?&\/=]*))$"
    ) = Field(
        ...,
        description="+label=Helm repository URL\n+sort=1\n+message=Needs to be a valid URL.",
    )
    integration_fqn: Optional[str] = Field(
        None,
        description='+docs=FQN of the helm repo integration. You can use the FQN of your desired helm integration (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations) page\n+label=Helm repo integration\n+sort=2\n+usage=FQN of the helm repo integration. If you can\'t find your integration here,\nadd it through the [Integrations](/integrations) page\n+uiType=IntegrationSelect\n+uiProps={"integrationType":"helm-repo"}',
    )
    chart: str = Field(
        ...,
        description='+label=Chart name\n+sort=3\n+usage=The helm chart name\n+uiType=InputSelect\n+uiProps={"creatable":true, "searchable":true}',
    )
    version: str = Field(
        ...,
        description='+label=Version\n+sort=4\n+usage=Helm chart version\n+uiType=InputSelect\n+uiProps={"creatable":true, "searchable":true}',
    )


class HttpProbe(BaseModel):
    """
    +docs=Describes the Instructions for assessing container health by executing an HTTP GET request.
    To learn more you can go [here](https://docs.truefoundry.com/docs/liveness-readiness-probe)
    +label=Instructions for assessing container health by executing an HTTP GET request.
    """

    type: Literal["http"] = Field(
        ..., description="+sort=1\n+label=Request Type\n+value=http"
    )
    path: str = Field(
        ..., description="+usage=Path to the health check endpoint\n+sort=2"
    )
    port: conint(ge=0, le=65535) = Field(
        ..., description="+usage=Listening port for the health check endpoint\n+sort=3"
    )
    host: Optional[str] = Field(
        None,
        description="+sort=4\n+usage=Host name to connect to, defaults to the pod IP",
    )
    scheme: str = Field(
        "HTTP", description="+sort=5\n+usage=Scheme to use for connecting to the host"
    )


class HuggingfaceArtifactSource(BaseModel):
    """
    +docs=Input for Artifact from Huggingface Model Hub
    +label=Huggingface Model Source
    """

    type: Literal["huggingface-hub"] = Field(..., description="+value=huggingface-hub")
    model_id: str = Field(
        ...,
        description="+label=Model ID\n+usage=Model ID of the artifact to be downloaded",
    )
    revision: str = Field(
        ...,
        description="+label=Revision\n+usage=Revision of the artifact to be downloaded",
    )
    ignore_patterns: List[str] = Field(
        ["*.h5", "*.ot", "*.tflite", "*.msgpack"],
        description="+label=Ignore Patterns\n+usage=List of patterns to ignore while downloading the artifact",
    )
    download_path_env_variable: str = Field(
        ...,
        description="+label=Download Path Environment Variable\n+usage=Environment variable which will contain the download path of the artifact",
    )


class Image(BaseModel):
    """
    +docs=Describes that we are using a pre-built image stored in a Docker Image registry
    +label=Docker Image (Deploy an existing image)
    +icon=fa-brands fa-docker:#0db7ed
    """

    type: Literal["image"] = Field(..., description="+value=image")
    image_uri: constr(regex=r"^\S*$") = Field(
        ...,
        description="+label=Image URI\n+usage=The image URI. Specify the name of the image and the tag.\nIf the image is in Dockerhub, you can skip registry-url (for e.g. `tensorflow/tensorflow`).\nYou can use an image from a private registry using Advanced fields\n+placeholder=registry-url/account/image:version (e.g. docker.io/tensorflow/tensorflow)",
    )
    docker_registry: Optional[str] = Field(
        None,
        description="+docs=FQN of the container registry. You can the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations?tab=docker-registry) page\n+label=Docker Registry\n+usage=FQN of the container registry. If you can't find your registry here,\nadd it through the [Integrations](/integrations?tab=docker-registry) page",
    )
    command: Optional[Union[str, List[str]]] = Field(
        None,
        description="+label=Command Override\n+usage=Override the command to run when container starts.\nWhen deploying a Job, the command can be templatized by defining `params` and referencing them in command\nE.g. `python main.py --learning_rate {{learning_rate}}`",
    )


class JobAlert(BaseModel):
    """
    +docs=Describes the configuration for the job alerts
    +label=Alert
    """

    notification_channel: constr(min_length=1) = Field(
        ...,
        description='+label=Notification Channel\n+usage=Specify the notification channel to send alerts to\n+uiType=IntegrationSelect\n+uiProps={"integrationType":"notification-channel"}\n+sort=660',
    )
    to_emails: Optional[List[constr(min_length=1)]] = Field(
        None,
        description="+label=To Emails\n+usage=List of recipients' email addresses if the notification channel is Email.\n+docs=Specify the emails to send alerts to\n+sort=665",
    )
    on_start: bool = Field(
        False,
        description="+label=On Start\n+usage=Send an alert when the job starts\n+sort=670",
    )
    on_completion: bool = Field(
        False,
        description="+label=On Completion\n+usage=Send an alert when the job completes\n+sort=680",
    )
    on_failure: bool = Field(
        True,
        description="+label=On Failure\n+usage=Send an alert when the job fails\n+sort=690",
    )


class Claim(BaseModel):
    key: str
    values: List[str]


class JwtAuthCreds(BaseModel):
    """
    +label=JWT Authentication
    +usage=Configure JWT-based authentication using JWKS
    """

    type: Literal["jwt_auth"] = Field(..., description="+value=jwt_auth")
    issuer: str = Field(
        ..., description="+label=Issuer\n+usage=The issuer of the JWT tokens"
    )
    jwksUri: str = Field(
        ...,
        description="+label=JWKS URI\n+usage=The URI of the JSON Web Key Set (JWKS) containing the public keys",
    )
    claims: Optional[List[Claim]] = Field(
        None,
        description="+label=Claims\n+usage=List of key-value pairs of claims to verify in the JWT token",
    )


class KafkaMetricConfig(BaseModel):
    type: Literal["kafka"] = Field(..., description="+value=kafka")
    lag_threshold: conint(ge=1) = Field(
        ...,
        description="+label=Lag Threshold\n+usage=Upper limit of the number of backlog messages the auto-scaler will try to maintain per replica. If you set this number to 10 and have 30 messages in the stream and one replica, the auto-scaler will scale the number of replicas to 3.",
    )


class KafkaSASLAuth(BaseModel):
    username: str = Field(
        ...,
        description="+label=Username\n+usage=Username for SASL authentication\n+sort=1",
    )
    password: str = Field(
        ...,
        description="+label=Password\n+usage=Password for SASL authentication\n+sort=2",
    )


class Kustomize(BaseModel):
    patch: Optional[Dict[str, Any]] = Field(
        None,
        description="+label=Patch\n+usage=Content of kustomization.yaml to perform kustomize operation. Please do not include the `resources` section. It is filled in automatically",
    )
    additions: Optional[List[Dict[str, Any]]] = Field(
        None,
        description="+label=Additional Manifests\n+usage=Additional kubernetes manifests to be included in the application",
    )


class LocalSource(BaseModel):
    """
    +docs=Describes that we are using code stored in a local developement environment to build our image
    +label=Local
    +icon=fa-folder:black
    +sort=100
    """

    type: Literal["local"] = Field(..., description="+value=local")
    project_root_path: str = Field("./", description="+usage=Local project root path.")
    local_build: bool = Field(True, description="run docker build locally")


class Manual(BaseModel):
    """
    +docs=Describes that we are going to manually trigger our job.
    +label=Manual
    +usage=Trigger the job manually. [Docs](https://docs.truefoundry.com/docs/deploy-a-cron-job)
    """

    type: Literal["manual"] = Field(..., description="+value=manual")


class NATSMetricConfig(BaseModel):
    type: Literal["nats"] = Field(..., description="+value=nats")
    lag_threshold: conint(ge=1) = Field(
        ...,
        description="+label=Lag Threshold\n+usage=Upper limit of the number of backlog messages the auto-scaler will try to maintain per replica. If you set this number to 10 and have 30 messages in the stream and one replica, the auto-scaler will scale the number of replicas to 3.",
    )


class NATSUserPasswordAuth(BaseModel):
    """
    +docs=NATS User Password Authentication
    +label=NATS User Password Authentication
    """

    account_name: str = Field(
        "$G",
        description="+label=Account Name\n+usage=Name of the NATS account\n+sort=1",
    )
    user: str = Field(
        ..., description="+label=User\n+usage=User for NATS authentication\n+sort=2"
    )
    password: str = Field(
        ...,
        description="+label=Password\n+usage=Password for NATS authentication\n+sort=3",
    )


class CapacityType(str, Enum):
    """
    +label=Capacity Type
    +usage=Configure what type of nodes to run the app. By default no placement logic is applied.
    "spot_fallback_on_demand" will try to place the application on spot nodes but will fallback to on-demand when spot nodes are not available.
    "spot" will strictly place the application on spot nodes.
    "on_demand" will strictly place the application on on-demand nodes.
    """

    spot_fallback_on_demand = "spot_fallback_on_demand"
    spot = "spot"
    on_demand = "on_demand"


class NodeSelector(BaseModel):
    """
    +label=Node selector
    +usage=Constraints to select a Node - Specific GPU / Instance Families, On-Demand/Spot.
    """

    type: Literal["node_selector"] = Field(..., description="+value=node_selector")
    gpu_type: Optional[str] = Field(
        None,
        description="+label=GPU Type\n+usage=Name of the Nvidia GPU. One of [P4, P100, V100, T4, A10G, A100_40GB, A100_80GB]\nOne instance of the card contains the following amount of memory -\nP4: 8 GB, P100: 16 GB, V100: 16 GB, T4: 16 GB, A10G: 24 GB, A100_40GB: 40GB, A100_80GB: 80 GB",
    )
    instance_families: Optional[List[str]] = Field(
        None,
        description="+label=Instance family\n+usage=Instance family of the underlying machine to use. Multiple instance families can be supplied.\nThe workload is guaranteed to be scheduled on one of them.",
    )
    capacity_type: Optional[CapacityType] = Field(
        None,
        description='+label=Capacity Type\n+usage=Configure what type of nodes to run the app. By default no placement logic is applied.\n"spot_fallback_on_demand" will try to place the application on spot nodes but will fallback to on-demand when spot nodes are not available.\n"spot" will strictly place the application on spot nodes.\n"on_demand" will strictly place the application on on-demand nodes.',
    )


class NodepoolSelector(BaseModel):
    """
    +label=Nodepool selector
    +usage=Specify one or more nodepools to run your application on.
    """

    type: Literal["nodepool_selector"] = Field(
        ..., description="+value=nodepool_selector"
    )
    nodepools: Optional[List[str]] = Field(
        None,
        description="+label=Nodepools\n+usage=Nodepools where you want to run your workload. Multiple nodepools can be selected.\n The workload is guaranteed to be scheduled on one of the nodepool",
    )


class NvidiaGPU(BaseModel):
    type: Literal["nvidia_gpu"] = Field(..., description="+value=nvidia_gpu")
    name: Optional[str] = Field(
        None,
        description="+label=GPU Name\n+usage=Name of the Nvidia GPU. One of [P4, P100, V100, T4, A10G, A100_40GB, A100_80GB]\nThis field is required for Node Selector and can be ignored in Nodepool Selector.\nOne instance of the card contains the following amount of memory -\nP4: 8 GB, P100: 16 GB, V100: 16 GB, T4: 16 GB, A10G: 24 GB, A100_40GB: 40GB, A100_80GB: 80 GB",
    )
    count: conint(ge=1, le=16) = Field(
        ...,
        description="+label=GPU Count\n+usage=Count of GPUs to provide to the application\nNote the exact count and max count available for a given GPU type depends on cloud provider and cluster type.",
    )


class Profile(str, Enum):
    """
    +label=MIG Profile
    +usage=Name of the MIG profile to use. One of [1g.5gb, 2g.10gb, 3g.20gb, 1g.10gb, 2g.20gb, 3g.40gb]
    """

    field_1g_5gb = "1g.5gb"
    field_2g_10gb = "2g.10gb"
    field_3g_20gb = "3g.20gb"
    field_1g_10gb = "1g.10gb"
    field_2g_20gb = "2g.20gb"
    field_3g_40gb = "3g.40gb"


class NvidiaMIGGPU(BaseModel):
    type: Literal["nvidia_mig_gpu"] = Field(..., description="+value=nvidia_mig_gpu")
    name: Optional[str] = Field(
        None,
        description="+label=GPU Name\n+usage=Name of the Nvidia GPU. One of [P4, P100, V100, T4, A10G, A100_40GB, A100_80GB]\nThis field is required for Node Selector and can be ignored in Nodepool Selector.\nOne instance of the card contains the following amount of memory -\nP4: 8 GB, P100: 16 GB, V100: 16 GB, T4: 16 GB, A10G: 24 GB, A100_40GB: 40GB, A100_80GB: 80 GB",
    )
    profile: Profile = Field(
        ...,
        description="+label=MIG Profile\n+usage=Name of the MIG profile to use. One of [1g.5gb, 2g.10gb, 3g.20gb, 1g.10gb, 2g.20gb, 3g.40gb]",
    )


class NvidiaTimeslicingGPU(BaseModel):
    type: Literal["nvidia_timeslicing_gpu"] = Field(
        ..., description="+value=nvidia_timeslicing_gpu"
    )
    name: Optional[str] = Field(
        None,
        description="+label=GPU Name\n+usage=Name of the Nvidia GPU. One of [P4, P100, V100, T4, A10G, A100_40GB, A100_80GB]\nThis field is required for Node Selector and can be ignored in Nodepool Selector.\nOne instance of the card contains the following amount of memory -\nP4: 8 GB, P100: 16 GB, V100: 16 GB, T4: 16 GB, A10G: 24 GB, A100_40GB: 40GB, A100_80GB: 80 GB",
    )
    gpu_memory: conint(ge=1, le=200000) = Field(
        ...,
        description="+label=GPU Memory (MB)\n+usage=Amount of GPU memory (in MB) to allocate. Please note, this limit is not being enforced today but will be in future. Applications are expected to operate in co-opertative mode",
    )


class OCIRepo(BaseModel):
    """
    +label=OCIRepo
    """

    type: Literal["oci-repo"] = Field(..., description="+value=oci-repo")
    oci_chart_url: constr(
        regex=r"^(((oci):\/\/)?(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}(?:[-a-zA-Z0-9()@:%_\+.~#?&\/=]*))$"
    ) = Field(..., description="+label=OCI chart URL\n+message=Need to be a valid URL.")
    integration_fqn: Optional[str] = Field(
        None,
        description='+docs=FQN of the container registry. You can use the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations) page\n+label=Container Registry\n+usage=FQN of the container registry. If you can\'t find your registry here,\nadd it through the [Integrations](/integrations) page\n+uiType=IntegrationSelect\n+uiProps={"integrationType":"docker-registry"}',
    )
    version: str = Field(..., description="+label=Version\n+usage=Helm chart version")


class ParamType(str, Enum):
    string = "string"
    ml_repo = "ml_repo"


class Param(BaseModel):
    name: constr(regex=r"^[a-z][a-z0-9\-_]{0,30}[a-z0-9]$") = Field(
        ...,
        description="+usage=Name of the param\n+message=name can contain lower case alphabets, digits, underscore (_) and hypen (-). It can be 32 characters long, should start with an alphabet, and should end with either an alphabet or digit.",
    )
    description: Optional[constr(regex=r"^.{1,127}$")] = Field(
        None,
        description="+usage=Description of param\n+message=description cannot be longer than 127 characters",
    )
    default: Optional[constr(regex=r"^.{0,127}$")] = Field(
        None,
        description="+usage=Default value or placeholder\n+message=default value cannot be longer than 127 characters\n+label=Default value",
    )
    param_type: ParamType = "string"


class Protocol(str, Enum):
    """
    +usage=Protocol for the port.
    """

    TCP = "TCP"
    UDP = "UDP"


class AppProtocol(str, Enum):
    """
    +label=Application Protocol
    +usage=Application Protocol for the port.
    Select the application protocol used by your service. For most use cases, this should be `http`(HTTP/1.1).
    If you are running a gRPC server, select the `grpc` option.
    This is only applicable if `expose=true`.
    """

    http = "http"
    grpc = "grpc"
    tcp = "tcp"


class PythonBuild(BaseModel):
    """
    +docs=Describes that we are using python to build a container image with a specific python version and pip packages installed.
    +label=Python Code (I don't have Dockerfile)
    +icon=fa-brands fa-python:#306998
    """

    type: Literal["tfy-python-buildpack"] = Field(
        ..., description="+value=tfy-python-buildpack"
    )
    python_version: constr(regex=r"^\d+(\.\d+){1,2}([\-\.a-z0-9]+)?$") = Field(
        "3.11",
        description="+label=Python version\n+usage=Python version to run your application. Should be one of the tags listed on [Official Python Docker Page](https://hub.docker.com/_/python)\n+message=Please enter a valid Python version tag",
    )
    build_context_path: str = Field(
        "./",
        description="+label=Path to build context\n+usage=Build path relative to project root path.",
    )
    requirements_path: Optional[str] = Field(
        None,
        description="`Path to build context`\n+label=Path to requirements\n+usage=Path to `requirements.txt` relative to\n`Path to build context`",
    )
    pip_packages: Optional[List[str]] = Field(
        None,
        description='+label=Pip packages to install\n+usage=Define pip package requirements.\nIn Python/YAML E.g. ["fastapi>=0.90,<1.0", "uvicorn"]\n+placeholder=Enter a pip package name E.g. fastapi>=0.90,<1.0',
    )
    apt_packages: Optional[List[str]] = Field(
        None,
        description='+label=List of Debian packages to install.\n+usage=Debian packages to install via `apt get`.\nIn Python/YAML E.g. ["git", "ffmpeg", "htop"]\n+placeholder=Enter a debian package name E.g. ffmpeg',
    )
    command: Union[str, List[str]] = Field(
        ...,
        description="Command will be set as the Entrypoint of the generated\nimage.\n+label=Command\n+usage=Command to run when the container starts.\nCommand will be set as the Entrypoint of the generated image.\nWhen deploying a Job, the command can be templatized by defining `params` and referencing them in command\nE.g. `python main.py --learning_rate {{learning_rate}}`",
    )
    cuda_version: Optional[
        constr(
            regex=r"^((\d+\.\d+(\.\d+)?-cudnn\d+-(runtime|devel)-ubuntu\d+\.\d+)|11\.0-cudnn8|11\.1-cudnn8|11\.2-cudnn8|11\.3-cudnn8|11\.4-cudnn8|11\.5-cudnn8|11\.6-cudnn8|11\.7-cudnn8|11\.8-cudnn8|12\.0-cudnn8|12\.1-cudnn8|12\.2-cudnn8)$"
        )
    ] = Field(
        None,
        description="+label=CUDA Version\n+usage=Version of CUDA Toolkit and CUDNN to install in the image\nThese combinations are based off of publically available docker images on docker hub\nYou can also specify a valid tag of the form {cuda_version_number}-cudnn{cudnn_version_number}-{runtime|devel}-ubuntu{ubuntu_version}\nRefer https://hub.docker.com/r/nvidia/cuda/tags for valid set of values\nNote: We use deadsnakes ubuntu ppa to add Python that currently supports only Ubuntu 18.04, 20.04 and 22.04",
    )


class RPSMetric(BaseModel):
    type: Literal["rps"] = Field(..., description="+value=rps")
    value: PositiveFloat = Field(
        ...,
        description="+label=Requests per second\n+usage=Average request per second averaged over all replicas that autoscaler should try to maintain",
    )


class RemoteSource(BaseModel):
    """
    +docs=Describes that we are using code stored in a remote respository to build our image
    +label=S3
    +icon=fa-brands fa-aws:black
    +sort=200
    """

    type: Literal["remote"] = Field(..., description="+value=remote")
    remote_uri: str = Field(
        ..., description="+docs=Remote repository URI\n+label=Remote URI"
    )


class Resources(BaseModel):
    """
    +docs=Describes the resource constraints for the application so that it can be deployed accordingly on the cluster
    To learn more you can go [here](https://docs.truefoundry.com/docs/resources)
    +icon=fa-microchip
    +label=Resources
    +usage=Configure resource allocations, specify node constraints and capacity types to improve performance and reduce expenses. [Docs](https://docs.truefoundry.com/docs/resources)
    """

    cpu_request: confloat(ge=0.001, le=256.0) = Field(
        0.2,
        description="+label=CPU Request\n+sort=1\n+usage=Requested CPU which determines the minimum cost incurred. The CPU usage can exceed the requested\namount, but not the value specified in the limit. 1 CPU means 1 CPU core. Fractional CPU can be requested\nlike `0.5` or `0.05`",
    )
    cpu_limit: confloat(ge=0.001, le=256.0) = Field(
        0.5,
        description="+label=CPU Limit\n+usage=CPU limit beyond which the usage cannot be exceeded. 1 CPU means 1 CPU core. Fractional CPU can be requested\nlike `0.5`. CPU limit should be >= cpu request.\n+sort=2",
    )
    memory_request: conint(ge=1, le=2000000) = Field(
        200,
        description="+label=Memory Request\n+usage=Requested memory which determines the minimum cost incurred. The unit of memory is in megabytes(MB).\nSo 1 means 1 MB and 2000 means 2GB.\n+sort=3",
    )
    memory_limit: conint(ge=1, le=2000000) = Field(
        500,
        description="+label=Memory Limit\n+usage=Memory limit after which the application will be killed with an OOM error. The unit of memory is\nin megabytes(MB). So 1 means 1 MB and 2000 means 2GB. MemoryLimit should be greater than memory request.\n+sort=4",
    )
    ephemeral_storage_request: conint(ge=1, le=2000000) = Field(
        1000,
        description="+label=Storage Request\n+usage=Requested disk storage. The unit of memory is in megabytes(MB).\nThis is ephemeral storage and will be wiped out on pod restarts or eviction\n+sort=5",
    )
    ephemeral_storage_limit: conint(ge=1, le=2000000) = Field(
        2000,
        description="+label=Storage Limit\n+usage=Disk storage limit. The unit of memory is in megabytes(MB). Exceeding this limit will result in eviction.\nIt should be greater than the request. This is ephemeral storage and will be wiped out on pod restarts or eviction\n+sort=6",
    )
    gpu_count: Optional[conint(ge=0, le=16)] = Field(
        None,
        description="+label=GPU Count\n+usage=Count of GPUs to provide to the application\nNote the exact count and max count available for a given GPU type depends on cloud provider and cluster type.",
    )
    shared_memory_size: Optional[conint(ge=64, le=2000000)] = Field(
        None,
        description="+label=Shared Memory Size (MB)\n+usage=Define the shared memory requirements for your workload. Machine learning libraries like Pytorch can use Shared Memory\nfor inter-process communication. If you use this, we will mount a `tmpfs` backed volume at the `/dev/shm` directory.\nAny usage will also count against the workload's memory limit (`resources.memory_limit`) along with your workload's memory usage.\nIf the overall usage goes above `resources.memory_limit` the user process may get killed.\nShared Memory Size cannot be more than the defined Memory Limit for the workload.",
    )
    node: Optional[Union[NodeSelector, NodepoolSelector]] = Field(
        None,
        description="+label=Node\n+usage=This field determines how the underlying node resource is to be utilized",
    )
    devices: Optional[
        List[
            Union[NvidiaGPU, AWSInferentia, NvidiaMIGGPU, NvidiaTimeslicingGPU, GcpTPU]
        ]
    ] = Field(
        None,
        description="+label=Devices\n+usage=Define custom device or accelerator requirements for your workload. We currently support NVIDIA GPUs, AWS Inferentia Accelerators, Single Host TPU Slices.",
    )


class Rolling(BaseModel):
    """
    +docs=This strategy updates the pods in a rolling fashion such that a subset of the
    total pods are replaced with new version at one time.
    A commonly used strategy can be to have maxUnavailablePercentage close to 0 so that there
    is no downtime and keep the maxSurgePercentage to around 25%. If you are anyways running
    a large number of pods, the service can often tolerate a few pods going down - so you
    max maxUnavailablePercentage = 10 and maxSurgePercentage=0. You can read about it more
    [here](https://spot.io/resources/kubernetes-autoscaling/5-kubernetes-deployment-strategies-roll-out-like-the-pros/)
    +label=Rolling update strategy
    """

    type: Literal["rolling_update"] = Field(..., description="+value=rolling_update")
    max_unavailable_percentage: conint(ge=0, le=100) = Field(
        25,
        description="+label=Max unavailable(%)\n+usage=Percentage of total replicas that can be brought down at one time.\nFor a value of 25 when replicas are set to 12 this would mean minimum (25% of 12) = 3 pods might be unavailable during the deployment.\nSetting this to a higher value can help in speeding up the deployment process.",
    )
    max_surge_percentage: conint(ge=0, le=100) = Field(
        25,
        description="+label=Max Surge(%)\n+usage=Percentage of total replicas of updated image that can be brought up over the total replicas count.\nFor a value of 25 when replicas are set to 12 this would mean (12+(25% of 12) = 15) pods might be running at one time.\nSetting this to a higher value can help in speeding up the deployment process.",
    )


class SQSInputConfig(BaseModel):
    """
    +docs=Describes the configuration for the input SQS worker
    +label=SQS
    """

    type: Literal["sqs"] = Field(..., description="+value=sqs")
    queue_url: str = Field(
        ...,
        description="+label=Queue URL\n+usage=AWS SQS Queue URL of Subscriber\n+sort=1",
    )
    region_name: str = Field(
        ..., description="+label=Region Name\n+usage=AWS Region Name\n+sort=2"
    )
    visibility_timeout: conint(ge=1, le=43200) = Field(
        ...,
        description="+label=Visibility Timeout (seconds)\n+usage=A period during which Amazon SQS prevents all consumers from receiving and processing the message. If one message takes 5 seconds to process, you can set this number to 7 or any number higher than 5. This will ensure that while the message is being processed, it will not be available to other replicas. For more information, see [here](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html)\n+sort=3",
    )
    wait_time_seconds: conint(ge=1, le=20) = Field(
        19,
        description="+label=Wait Time Seconds\n+usage=Wait timeout for long polling. For more information, see [here](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-short-and-long-polling.html)",
    )
    auth: AWSAccessKeyAuth


class SQSOutputConfig(BaseModel):
    """
    +docs=Describes the configuration for the output SQS worker
    +label=SQS
    """

    type: Literal["sqs"] = Field(..., description="+value=sqs")
    queue_url: str = Field(
        ...,
        description="+label=Queue URL\n+usage=AWS SQS Queue URL of Publisher\n+sort=1",
    )
    region_name: str = Field(
        ..., description="+label=Region Name\n+usage=AWS Region Name\n+sort=2"
    )
    auth: AWSAccessKeyAuth


class SQSQueueMetricConfig(BaseModel):
    type: Literal["sqs"] = Field(..., description="+value=sqs")
    queue_length: conint(ge=1) = Field(
        ...,
        description="+label=Queue length\n+usage=Upper limit of the number of backlog messages the auto-scaler will try to maintain per replica. If you set this number to 10 and have 30 messages in the queue and one replica, the auto-scaler will scale the number of replicas to 3.",
    )


class ConcurrencyPolicy(str, Enum):
    """
    +usage=Choose whether to allow this job to run while another instance of the job is running, or to replace the currently running instance. Allow
    will enable multiple instances of this job to run. Forbid will keep the current instance of the job running and stop a new instance from being run.
    Replace will terminate any currently running instance of the job and start a new one.
    """

    Forbid = "Forbid"
    Allow = "Allow"
    Replace = "Replace"


class Schedule(BaseModel):
    """
    +docs=Describes that we are going to schedule our job to run at a schedule, making our job a cron job.
    +label=Schedule
    +usage=Run the job on a schedule. [Docs](https://docs.truefoundry.com/docs/deploy-a-cron-job)
    """

    type: Literal["scheduled"] = Field(..., description="+value=scheduled")
    schedule: str = Field(
        ...,
        description="+docs=Specify the schedule for this job to be run periodically in cron format. [Learn more](https://docs.truefoundry.com/docs/deploy-a-cron-job)\n+usage=Specify the schedule for this job to be run periodically in cron format.\n```\n* * * * *\n| | | | |\n| | | | |___ day of week (0-6) (Sunday is 0)\n| | | |_____ month (1-12)\n| | |_______ day of month (1-31)\n| |_________ hour (0-23)\n|___________ minute (0-59)\n```",
    )
    concurrency_policy: ConcurrencyPolicy = Field(
        "Forbid",
        description="+usage=Choose whether to allow this job to run while another instance of the job is running, or to replace the currently running instance. Allow\nwill enable multiple instances of this job to run. Forbid will keep the current instance of the job running and stop a new instance from being run.\nReplace will terminate any currently running instance of the job and start a new one.",
    )
    timezone: Optional[str] = Field(
        None,
        description='+usage=Timezone against which the cron schedule will be calculated, e.g. "Asia/Tokyo". Default is machine\'s local time.\nhttps://docs.truefoundry.com/docs/list-of-supported-timezones',
    )


class SecretMount(BaseModel):
    type: Literal["secret"] = Field(..., description="+value=secret")
    mount_path: constr(regex=r"^\/(?:[^/\n]+\/*)*[^/\n]+(\.[^/\n]+)?$") = Field(
        ...,
        description="+label=File path\n+usage=Absolute file path where the file will be created.\n+message=Please enter a valid file path",
    )
    secret_fqn: constr(regex=r"^tfy-secret:\/\/.+:.+:.+$") = Field(
        ...,
        description="+label=Secret\n+usage=The TrueFoundry secret whose value will be the file content.",
    )


class ServiceAutoscaling(BaseAutoscaling):
    metrics: Union[CPUUtilizationMetric, RPSMetric, CronMetric] = Field(
        ...,
        description="+label=Autoscaling metrics\n+usage=Metrics to use for the autoscaler\n+sort=4",
    )


class SparkDriverConfig(BaseModel):
    """
    +label=Driver Config
    """

    ui_endpoint: Endpoint
    resources: Optional[Resources] = None


class SparkExecutorDynamicScaling(BaseModel):
    """
    +label=Dynamic Scaling
    """

    type: Literal["dynamic"] = Field(..., description="+value=dynamic")
    min: conint(ge=0, le=500) = Field(
        1,
        description="+label=Min Instances\n+usage=Minimum number of instances to start / scale down to\n+sort=100",
    )
    max: conint(ge=0, le=500) = Field(
        1,
        description="+label=Max Instances\n+usage=Maximum number of instances to scale up to\n+sort=200",
    )


class SparkExecutorFixedInstances(BaseModel):
    """
    +label=Fixed Instances
    """

    type: Literal["fixed"] = Field(..., description="+value=fixed")
    count: conint(ge=0, le=500) = Field(
        1, description="+label=Instances Count\n+usage=Number of instances to start"
    )


class StaticVolumeConfig(BaseModel):
    """
    +label=Static Volume Config
    """

    type: Literal["static"] = Field(
        ...,
        description="+label=Volume Type\n+value=static\n+usage=Volume Type for the volume.",
    )
    persistent_volume_name: str = Field(
        ...,
        description="+label=Persistent Volume\n+usage=Persistent Volume Name of the volume to be used.",
    )


class StringDataMount(BaseModel):
    type: Literal["string"] = Field(..., description="+value=string")
    mount_path: constr(regex=r"^\/(?:[^/\n]+\/*)*[^/\n]+(\.[^/\n]+)?$") = Field(
        ...,
        description="+label=File Path\n+usage=Absolute file path where the file will be created.\n+message=Please enter a valid file path",
    )
    data: str = Field(..., description="+label=Data\n+usage=The file content.")


class TaskDockerFileBuild(BaseModel):
    """
    +docs=Describes the configuration for the docker build for a task
    +label=Docker File
    +icon=fa-brands fa-docker:#0db7ed
    """

    type: Literal["task-dockerfile-build"] = Field(..., description="+value=dockerfile")
    docker_registry: Optional[str] = Field(
        None,
        description="+docs=FQN of the container registry. You can the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations?tab=docker-registry) page\n+label=Docker Registry\n+usage=FQN of the container registry. If you can't find your registry here,\nadd it through the [Integrations](/integrations?tab=docker-registry) page",
    )
    dockerfile_path: str = Field(
        "./Dockerfile",
        description="+label=Path to Dockerfile\n+usage=The file path of the Dockerfile relative to project root path.",
    )
    build_args: Optional[Dict[str, str]] = Field(
        None, description="+label=Build arguments to pass to docker build"
    )


class TaskPythonBuild(BaseModel):
    """
    +docs=Describes the configuration for the python build for a task
    +label=Python Buid Spec
    +icon=fa-brands fa-python:#306998
    """

    type: Literal["task-python-build"] = Field(
        ..., description="+value=task-python-build"
    )
    docker_registry: Optional[str] = Field(
        None,
        description="+docs=FQN of the container registry. You can the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations?tab=docker-registry) page\n+label=Docker Registry\n+usage=FQN of the container registry. If you can't find your registry here,\nadd it through the [Integrations](/integrations?tab=docker-registry) page",
    )
    python_version: constr(regex=r"^\d+(\.\d+){1,2}([\-\.a-z0-9]+)?$") = Field(
        "3.11",
        description="+label=Python version\n+usage=Python version to run your application. Should be one of the tags listed on [Official Python Docker Page](https://hub.docker.com/_/python)\n+message=Please enter a valid Python version tag",
    )
    requirements_path: Optional[str] = Field(
        None,
        description="`Path to build context`\n+label=Path to requirements\n+usage=Path to `requirements.txt` relative to\n`Path to build context`",
    )
    pip_packages: Optional[List[str]] = Field(
        None,
        description='+label=Pip packages to install\n+usage=Define pip package requirements.\nIn Python/YAML E.g. ["fastapi>=0.90,<1.0", "uvicorn"]\n+placeholder=Enter a pip package name E.g. fastapi>=0.90,<1.0',
    )
    apt_packages: Optional[List[str]] = Field(
        None,
        description='+label=List of Debian packages to install.\n+usage=Debian packages to install via `apt get`.\nIn Python/YAML E.g. ["git", "ffmpeg", "htop"]\n+placeholder=Enter a debian package name E.g. ffmpeg',
    )
    cuda_version: Optional[
        constr(
            regex=r"^((\d+\.\d+(\.\d+)?-cudnn\d+-(runtime|devel)-ubuntu\d+\.\d+)|11\.0-cudnn8|11\.1-cudnn8|11\.2-cudnn8|11\.3-cudnn8|11\.4-cudnn8|11\.5-cudnn8|11\.6-cudnn8|11\.7-cudnn8|11\.8-cudnn8|12\.0-cudnn8|12\.1-cudnn8|12\.2-cudnn8)$"
        )
    ] = Field(
        None,
        description="+label=CUDA Version\n+usage=Version of CUDA Toolkit and CUDNN to install in the image\nThese combinations are based off of publically available docker images on docker hub\nYou can also specify a valid tag of the form {cuda_version_number}-cudnn{cudnn_version_number}-{runtime|devel}-ubuntu{ubuntu_version}\nRefer https://hub.docker.com/r/nvidia/cuda/tags for valid set of values\nNote: We use deadsnakes ubuntu ppa to add Python that currently supports only Ubuntu 18.04, 20.04 and 22.04",
    )


class TrueFoundryArtifactSource(BaseModel):
    """
    +docs=Input for Artifact from TrueFoundry Artifact Registry
    +label=TrueFoundry Artifact Source
    """

    type: Literal["truefoundry-artifact"] = Field(
        ..., description="+value=truefoundry-artifact"
    )
    artifact_version_fqn: str = Field(
        ...,
        description="+label=Artifact or Model Version FQN\n+usage=Artifact or Model Version FQN of the artifact to be downloaded",
    )
    download_path_env_variable: str = Field(
        ...,
        description="+label=Download Path Environment Variable\n+usage=Environment variable which will contain the download path of the artifact",
    )


class TrueFoundryInteractiveLogin(BaseModel):
    """
    +label=Login with truefoundry
    """

    type: Literal["truefoundry_oauth"] = Field(
        ..., description="+value=truefoundry_oauth"
    )


class VolumeBrowser(BaseModel):
    """
    +label=Volume Browser
    """

    username: constr(regex=r"^[a-z][a-z0-9]{1,8}[a-z0-9]$") = Field(
        ...,
        description="+message=3 to 10 lower case characters long alphanumeric word, may contain - in between, cannot start with a number.\n+usage=Username for logging in the volume browser.\n+sort=1",
    )
    password_secret_fqn: constr(regex=r"^tfy-secret:\/\/.+:.+:.+$") = Field(
        ...,
        description="+label=Password Secret FQN\n+usage=TFY Secret containing the password for logging in the volume browser.\n+sort=2",
    )
    endpoint: Endpoint
    service_account: Optional[str] = Field(
        None,
        description="+label=Service Account Name\n+usage=Kubernetes Service account name for the volume browser.\n+sort=4",
    )


class VolumeMount(BaseModel):
    type: Literal["volume"] = Field(..., description="+value=volume")
    mount_path: constr(regex=r"^\/(?:[^/\n]+\/*)*[^/\n]+(\.[^/\n]+)?$") = Field(
        ...,
        description="+label=Volume mount path\n+usage=Absolute file path where the volume will be mounted.\n+message=Please enter a valid mount path",
    )
    sub_path: Optional[constr(regex=r"^(?:[^/\n]+/*)*[^/\n]+(\.[^/\n]+)?$")] = Field(
        None,
        description="+label=Sub Path\n+usage=Sub path within the volume to mount. Defaults to root of the volume.",
    )
    volume_fqn: constr(regex=r"^tfy-volume:\/\/.+:.+:.+$") = Field(
        ...,
        description="+label=Volume\n+usage=The TrueFoundry volume that needs to be mounted.",
    )


class WorkbenchImage(BaseModel):
    """
    +usage=Workbench Image with persistent environment (Python 3.11.6)
    """

    image_uri: str = Field(
        ...,
        description="+label=Image URI\n+usage=The image URI. Specify the name of the image and the tag.\nIf the image is in Dockerhub, you can skip registry-url (for e.g. `tensorflow/tensorflow`).\nYou can use an image from a private registry using Advanced fields\n+placeholder=registry-url/account/image:version",
    )
    build_script: Optional[constr(min_length=1, max_length=1024)] = Field(
        None,
        description='+label=Build Script\n+usage=The build script to run when building the image.\nThis will be executed as the last step in the docker build process as the root user (RUN DEBIAN_FRONTEND=noninteractive bash -ex build_script.sh)\n+placeholder=Enter the build script\n+uiType=CodeEditor\n+uiProps={"language":"shell"}',
    )
    docker_registry: Optional[str] = Field(
        None,
        description='+docs=FQN of the container registry. You can the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations?tab=docker-registry) page\n+label=Docker Registry\n+uiType=IntegrationSelect\n+uiProps={"integrationType":"docker-registry"}\n+usage=FQN of the container registry. If you can\'t find your registry here,\nadd it through the [Integrations](/integrations?tab=docker-registry) page',
    )


class ArtifactsDownload(BaseModel):
    """
    +docs=Describes the configuration for the artifacts cache
    +label=Artifacts Download
    +usage=Download and cache models in a volume to enhance loading speeds and reduce costs by avoiding repeated downloads. [Docs](https://docs.truefoundry.com/docs/download-and-cache-models)
    """

    cache_volume: Optional[ArtifactsCacheVolume] = None
    artifacts: List[Union[TrueFoundryArtifactSource, HuggingfaceArtifactSource]] = (
        Field(
            ..., description="+label=Artifacts\n+usage=List of artifacts to be cached"
        )
    )


class AsyncServiceAutoscaling(BaseAutoscaling):
    metrics: Union[
        SQSQueueMetricConfig,
        NATSMetricConfig,
        KafkaMetricConfig,
        CronMetric,
        AMQPMetricConfig,
    ] = Field(
        ...,
        description="+label=Autoscaling metrics\n+usage=Metrics to use for the autoscaler\n+sort=4",
    )


class BaseWorkbenchInput(BaseModel):
    """
    +docs=Describes the configuration for the service
    """

    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+usage=Name of the workbench. This uniquely identifies this workbench in the workspace.\n> Name can only contain alphanumeric characters and '-' and can be atmost 25 characters long\n+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number",
    )
    home_directory_size: conint(ge=5, le=64000) = Field(
        20,
        description="+label=Home Directory Size in GB (Persistent)\n+usage=Size of the home directory for the workbench (Persistent Storage)\n+sort=6",
    )
    resources: Optional[Resources] = None
    env: Optional[Dict[str, str]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the service either as plain text or secrets. [Docs](https://docs.truefoundry.com/docs/environment-variables-and-secrets-jobs)\n+sort=10110",
    )
    mounts: Optional[List[Union[SecretMount, StringDataMount, VolumeMount]]] = Field(
        None,
        description="+usage=Configure data to be mounted to workbench pod(s) as a string, secret or volume. [Docs](https://docs.truefoundry.com/docs/mounting-volumes-job)\n+sort=10111",
    )
    service_account: Optional[str] = Field(None, description="+sort=10113")
    kustomize: Optional[Kustomize] = None
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class Build(BaseModel):
    """
    +docs=Describes how we build our code into a Docker image.
    +label=Source Code (Build and deploy source code)
    +icon=fa-code
    """

    type: Literal["build"] = Field(..., description="+value=build")
    docker_registry: Optional[str] = Field(
        None,
        description="+docs=FQN of the container registry. You can the FQN of your desired container registry (or add one)\nin the  Integrations page[Integrations](https://app.truefoundry.tech/integrations?tab=docker-registry) page\n+label=Docker Registry\n+usage=FQN of the container registry. If you can't find your registry here,\nadd it through the [Integrations](/integrations?tab=docker-registry) page",
    )
    build_source: Union[RemoteSource, GitSource, LocalSource] = Field(
        ...,
        description="+docs=Source code location.\n+label=Fetch source code to build and deploy\n+icon=fa-code\n+sort=1",
    )
    build_spec: Union[DockerFileBuild, PythonBuild] = Field(
        ...,
        description="+docs=Instructions to build a container image out of the build source\n+label=Build using DockerFile or using Buildpack\n+icon=fa-wrench\n+sort=2",
    )


class Canary(BaseModel):
    """
    +docs=This strategy brings up the new release without bringing the older release down. Traffic is shifted from the older release to the newer release in a staged manner.
    This can help with verifying the health of the new release without shifting complete traffic.
    +label=Canary strategy
    """

    type: Literal["canary"] = Field(..., description="+value=canary")
    steps: List[CanaryStep] = Field(
        ...,
        description="+docs=These steps would be executed in order to enable shifting of traffic slowly from stable to canary version\n+label=Steps",
    )


class Codeserver(BaseWorkbenchInput):
    """
    +docs=Describes the configuration for the code server
    """

    type: Literal["codeserver"] = Field(..., description="+value=codeserver")
    image: WorkbenchImage


class ContainerTaskConfig(BaseModel):
    type: Literal["container-task-config"] = Field(
        ..., description="+value=container-task-config"
    )
    image: Union[Build, Image] = Field(
        ...,
        description="+docs=Specify whether you want to deploy a Docker image or build and deploy from source code\n+label=Deploy a Docker image or build and deploy from source code\n+icon=fa-solid fa-cloud-arrow-up:#21B6A8\n+sort=200",
    )
    env: Optional[Dict[str, str]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the task either as plain text or secrets. [Docs](https://docs.truefoundry.com/docs/env-variables)\n+icon=fa-globe\n+sort=200",
    )
    resources: Optional[Resources] = None
    mounts: Optional[List[Union[SecretMount, StringDataMount, VolumeMount]]] = Field(
        None,
        description="+usage=Configure data to be mounted to Workflow pod(s) as a volume.\n+sort=400",
    )
    service_account: Optional[str] = Field(
        None, description="+label=Service Account\n+sort=500"
    )


class CoreNATSOutputConfig(BaseModel):
    """
    +docs=Describes the configuration for the output Core NATS worker
    +label=Core NATS
    """

    type: Literal["core-nats"] = Field(..., description="+value=core-nats")
    nats_url: str = Field(
        ..., description="+label=NATS URL\n+usage=Output NATS URL\n+sort=1"
    )
    root_subject: constr(regex=r"^[a-zA-Z0-9][a-zA-Z0-9\-.]+[a-zA-Z0-9]$") = Field(
        ...,
        description="+label=Root Subject\n+usage=Root subject of output NATS\n+message=Output NATS root subject should only contain alphanumeric letters, dashes(-), and periods(.)\n+sort=2",
    )
    auth: Optional[NATSUserPasswordAuth] = None


class FlyteLaunchPlanSpec(BaseModel):
    workflowId: FlyteWorkflowID


class FlyteWorkflow(BaseModel):
    template: FlyteWorkflowTemplate
    description: Optional[Any] = None


class HealthProbe(BaseModel):
    """
    +docs=Describes the configuration for the Health Probe's
    To learn more you can go [here](https://docs.truefoundry.com/docs/liveness-readiness-probe)
    +icon=fa-heart
    +uiType=HealthProbe
    """

    config: HttpProbe
    initial_delay_seconds: conint(ge=0, le=36000) = Field(
        0,
        description="+usage=Time to wait after container has started before checking the endpoint",
    )
    period_seconds: conint(ge=1, le=36000) = Field(
        10, description="+usage=How often to check the endpoint"
    )
    timeout_seconds: conint(ge=1, le=36000) = Field(
        1,
        description="+usage=Time to wait for a response from the endpoint before considering it down",
    )
    success_threshold: conint(ge=1, le=100) = Field(
        1,
        description="+usage=Number of successful responses from the endpoint before container is considered healthy",
    )
    failure_threshold: conint(ge=1, le=100) = Field(
        3,
        description="+usage=Number of consecutive failures before the container is considered down",
    )


class Helm(BaseModel):
    type: Literal["helm"] = Field(..., description="+value=helm")
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number\n+usage=Name of the Helm deployment. This will be set as the release name of the chart you are deploying.",
    )
    labels: Optional[Dict[str, str]] = Field(
        None, description="+label=Labels\n+usage=Add labels to base argo app"
    )
    source: Union[HelmRepo, OCIRepo, GitHelmRepo] = Field(
        ..., description="+label=Source helm repository\n+sort=2"
    )
    values: Optional[Dict[str, Any]] = Field(
        None, description="+label=Values\n+usage=Values file as block file"
    )
    kustomize: Optional[Kustomize] = None
    ignoreDifferences: Optional[List[Dict[str, Any]]] = None
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class Job(BaseModel):
    """
    +docs=Describes the configuration for the job
    """

    type: Literal["job"] = Field(..., description="+value=job")
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+usage=Name of the job\n+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number",
    )
    image: Union[Build, Image] = Field(
        ...,
        description="+docs=Specify whether you want to deploy a Docker image or build and deploy from source code\n+label=Deploy a Docker image or build and deploy from source code\n+icon=fa-solid fa-cloud-arrow-up:#21B6A8\n+sort=200",
    )
    trigger: Union[Manual, Schedule] = Field(
        {"type": "manual"}, description="+docs=Specify the trigger\n+sort=300"
    )
    trigger_on_deploy: bool = Field(
        False,
        description="+docs=Trigger on deploy\n+sort=350\n+usage=Trigger the job after deploy immediately",
    )
    params: Optional[List[Param]] = Field(
        None,
        description="+label=Params for input\n+usage=Configure params and pass it to create different job runs\n+sort=400",
    )
    env: Optional[Dict[str, str]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the service either as plain text or secrets. [Docs](https://docs.truefoundry.com/docs/env-variables)\n+icon=fa-globe\n+sort=500",
    )
    resources: Optional[Resources] = None
    alerts: Optional[List[JobAlert]] = Field(
        None,
        description="+label=Alerts\n+usage=Configure alerts to be sent when the job starts/fails/completes\n+icon=fa-bell\n+sort=650",
    )
    retries: conint(ge=0, le=10) = Field(
        0,
        description="+label=Retries\n+usage=Specify the maximum number of attempts to retry a job before it is marked as failed.\n+icon=fa-repeat\n+sort=700",
    )
    timeout: Optional[conint(le=432000, gt=0)] = Field(
        None,
        description="+label=Timeout\n+usage=Job timeout in seconds.\n+icon=fa-clock\n+sort=800",
    )
    concurrency_limit: Optional[PositiveInt] = Field(
        None,
        description="+label=Concurrency Limit\n+usage=Number of runs that can run concurrently\n+icon=fa-copy\n+sort=900",
    )
    service_account: Optional[str] = Field(None, description="+sort=1000")
    mounts: Optional[List[Union[SecretMount, StringDataMount, VolumeMount]]] = Field(
        None,
        description="+usage=Configure data to be mounted to job pod(s) as a string, secret or volume. [Docs](https://docs.truefoundry.com/docs/mounting-volumes-job)",
    )
    labels: Optional[Dict[str, str]] = Field(None, description="+label=Labels")
    kustomize: Optional[Kustomize] = None
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class KafkaInputConfig(BaseModel):
    """
    +docs=Describes the configuration for the input Kafka worker
    +label=Kafka
    """

    type: Literal["kafka"] = Field(..., description="+value=kafka")
    bootstrap_servers: str = Field(
        ...,
        description="+label=Bootstrap servers\n+usage='Kafka Bootstrap servers - Comma separated list of Kafka brokers \"hostname:port\" to connect to for bootstrap'\n+sort=1",
    )
    topic_name: str = Field(
        ...,
        description="+label=Topic Name\n+usage=Kafka topic to subscribe to\n+sort=2",
    )
    consumer_group: str = Field(
        ...,
        description="+label=Consumer Group Name\n+usage=The name of the consumer group to join for dynamic partition assignment\n+sort=3",
    )
    tls: bool = Field(
        True, description="+label=TLS\n+usage=TLS configuration for SASL authentication"
    )
    wait_time_seconds: conint(ge=1, le=300) = Field(
        10,
        description="+label=Wait Time Seconds\n+usage=Wait timeout for long polling.",
    )
    auth: Optional[KafkaSASLAuth] = None


class KafkaOutputConfig(BaseModel):
    """
    +docs=Describes the configuration for the output Kafka worker
    +label=Kafka
    """

    type: Literal["kafka"] = Field(..., description="+value=kafka")
    bootstrap_servers: str = Field(
        ...,
        description="+label=Bootstrap servers\n+usage='Kafka Bootstrap servers - Comma separated list of Kafka brokers \"hostname:port\" to connect to for bootstrap'\n+sort=1",
    )
    topic_name: str = Field(
        ..., description="+label=Topic Name\n+usage=Kafka topic to publish to\n+sort=2"
    )
    tls: bool = Field(
        True, description="+label=TLS\n+usage=TLS configuration for SASL authentication"
    )
    auth: Optional[KafkaSASLAuth] = None


class NATSInputConfig(BaseModel):
    """
    +docs=Describes the configuration for the input NATS worker
    +label=NATS
    """

    type: Literal["nats"] = Field(..., description="+value=nats")
    nats_url: str = Field(
        ..., description="+label=NATS URL\n+usage=Input NATS URL\n+sort=1"
    )
    stream_name: str = Field(
        ..., description="+label=Stream Name\n+usage=Name of the NATS stream\n+sort=2"
    )
    root_subject: constr(regex=r"^[a-zA-Z0-9][a-zA-Z0-9\-.]+[a-zA-Z0-9]$") = Field(
        ...,
        description="+label=Root Subject\n+usage=Root subject of input NATS\n+message=Input NATS root subject should only contain alphanumeric letters, dashes(-), and periods(.)\n+sort=3",
    )
    consumer_name: constr(regex=r"^[a-zA-Z0-9][a-zA-Z0-9\-_]+[a-zA-Z0-9]$") = Field(
        ...,
        description="+label=Consumer Name\n+usage=Consumer name of input NATS\n+message=Consumer name should only contain alphanumeric letters, dashes(-), and underscores(_)\n+sort=4",
    )
    wait_time_seconds: conint(ge=1, le=20) = Field(
        19,
        description="+label=Wait Time Seconds\n+usage=Wait timeout for long polling.\n+sort=5",
    )
    nats_metrics_url: Optional[constr(regex=r"^(http(s?)://).*$")] = Field(
        None,
        description="+label=NATS metrics URL\n+usage=URL for the NATS metrics endpoint. It is compulsory if you want to use NATS autoscaling.\n+message=NATS Metrics URL should be a valid HTTP/HTTPS URL",
    )
    auth: Optional[NATSUserPasswordAuth] = None


class NATSOutputConfig(BaseModel):
    """
    +docs=Describes the configuration for the output NATS worker
    +label=NATS
    """

    type: Literal["nats"] = Field(..., description="+value=nats")
    nats_url: str = Field(
        ..., description="+label=NATS URL\n+usage=Output NATS URL\n+sort=1"
    )
    root_subject: constr(regex=r"^[a-zA-Z0-9][a-zA-Z0-9\-.]+[a-zA-Z0-9]$") = Field(
        ...,
        description="+label=Root Subject\n+usage=Root subject of output NATS\n+message=Output NATS root subject should only contain alphanumeric letters, dashes(-), and periods(.)\n+sort=2",
    )
    auth: Optional[NATSUserPasswordAuth] = None


class Notebook(BaseWorkbenchInput):
    """
    +docs=Describes the configuration for the service
    """

    type: Literal["notebook"] = Field(..., description="+value=notebook")
    image: WorkbenchImage
    cull_timeout: conint(ge=5) = Field(
        30,
        description='+label=Stop after (minutes of inactivity)\n+usage=Stop the notebook instance after this much time in minutes of inactivity.\nThe notebook instance will be stopped even if the notebook is open in your browser, but nothing is running on the notebook.\n+sort=5\n+uiProps={"descriptionInline":true}',
    )


class Port(BaseModel):
    """
    +docs=Describes the ports the service should be exposed to.
    """

    port: conint(ge=1, le=65535) = Field(
        80, description="+usage=Port number to expose."
    )
    protocol: Protocol = Field("TCP", description="+usage=Protocol for the port.")
    expose: bool = Field(True, description="+usage=Expose the port")
    app_protocol: AppProtocol = Field(
        "http",
        description="+label=Application Protocol\n+usage=Application Protocol for the port.\nSelect the application protocol used by your service. For most use cases, this should be `http`(HTTP/1.1).\nIf you are running a gRPC server, select the `grpc` option.\nThis is only applicable if `expose=true`.",
    )
    host: Optional[
        constr(
            regex=r"^((([a-zA-Z0-9\-]{1,63}\.)([a-zA-Z0-9\-]{1,63}\.)*([A-Za-z]{1,63}))|(((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))$"
        )
    ] = Field(
        None,
        description="+usage=Host e.g. ai.example.com, app.truefoundry.com\n+message=Upto 253 characters, each part of host should be at most 63 characters long, can contain alphabets, digits and hypen, must begin and end with an alphanumeric characters. Parts must be separated by periods (.)",
    )
    path: Optional[
        constr(regex=r"^(/([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-_\.]*[a-zA-Z0-9]))*/$")
    ] = Field(
        None,
        description="+usage=Path e.g. /v1/api/ml/, /v2/docs/\n+message=Should begin and end with a forward slash (/). Each part can can contain alphabets, digits and hypen, must begin and end with an alphanumeric characters. Parts should be separated by forward slashes (/)",
    )
    rewrite_path_to: Optional[
        constr(regex=r"^(/([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-_\.]*[a-zA-Z0-9]))*/$")
    ] = Field(
        None,
        description="+label=Rewrite Path to\n+usage=Rewrite the path prefix to a different path.\nIf `path` is `/v1/api` and `rewrite_path_to` is `/api`. The URI in the HTTP request `http://0.0.0.0:8080/v1/api/houses` will be rewritten to `http://0.0.0.0:8080/api/houses` before the request is forwarded your service.\nDefaults to `/`.\nThis is only applicable if `path` is given.\n+message=Should begin and end with a forward slash (/). Each part can can contain alphabets, digits and hypen, must begin and end with an alphanumeric characters. Parts should be separated by forward slashes (/)",
    )
    auth: Optional[Union[BasicAuthCreds, JwtAuthCreds, TrueFoundryInteractiveLogin]] = (
        Field(None, description="+usage=Authentication method for inbound traffic")
    )


class PythonTaskConfig(BaseModel):
    """
    +docs=Describes the configuration for the python function task
    """

    type: Literal["python-task-config"] = Field(
        ..., description="+value=python-task-config"
    )
    image: Union[TaskPythonBuild, TaskDockerFileBuild] = Field(
        ...,
        description="+label=Image Spec\n+docs=Specification for the image to be used for the task\n+sort=100\n+usage=Specify the image spec for the task",
    )
    env: Optional[Dict[str, str]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the task either as plain text or secrets. [Docs](https://docs.truefoundry.com/docs/env-variables)\n+icon=fa-globe\n+sort=200",
    )
    resources: Optional[Resources] = None
    mounts: Optional[List[Union[SecretMount, StringDataMount, VolumeMount]]] = Field(
        None,
        description="+usage=Configure data to be mounted to Workflow pod(s) as a volume.\n+sort=400",
    )
    service_account: Optional[str] = Field(
        None, description="+label=Service Account\n+sort=500"
    )


class RStudio(BaseWorkbenchInput):
    """
    +docs=Describes the configuration for the Rstudio server
    """

    type: Literal["rstudio"] = Field(..., description="+value=rstudio")
    image: WorkbenchImage


class SSHServer(BaseWorkbenchInput):
    """
    +docs=Describes the configuration for the ssh server
    """

    type: Literal["ssh-server"] = Field(..., description="+value=ssh-server")
    image: WorkbenchImage
    ssh_public_key: str = Field(
        ...,
        description="+label: SSH Public Key\n+usage=Add Your SSH Public Key, this will be used to authenticate you to the SSH Server.  \\\nYou can find it using `cat ~/.ssh/id_rsa.pub` in Mac/Linux or `type $home\\.ssh\\id_rsa.pub` in Windows Powershell.  \\\nYou can also generate a new SSH key pair using `ssh-keygen -t rsa` in your local terminal. (same for both Mac/Linux and Windows Powershell)\n+uiType=TextArea\n+sort=4",
    )
    cull_timeout: Optional[conint(ge=5)] = Field(
        None,
        description='+label=Stop after (minutes of inactivity)\n+usage=Stop the SSH Server instance after this much time in minutes of inactivity. The instance is considered active if there is at least one active SSH connection (a client connected to the SSH server), or if a background job is running using tmux or screen, or if the pod has restarted.\n+sort=5\n+uiProps={"descriptionInline":true, "warningMessage":"Please note that stop after inactivity is only available for images with tag(including custom images) >= v0.3.10"}',
    )


class SparkExecutorConfig(BaseModel):
    """
    +label=Executor Config
    """

    instances: Union[SparkExecutorFixedInstances, SparkExecutorDynamicScaling] = Field(
        {"type": "fixed", "count": 1}, description="+label=Executor Instances"
    )
    resources: Optional[Resources] = None


class SparkJob(BaseModel):
    type: Literal["spark-job"] = Field(..., description="+value=spark-job\n+sort=1")
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+label=Name\n+usage=Name of the job\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number\n+sort=2",
    )
    image: Image
    spark_version: str = Field(
        "3.5.2",
        description="+label=Spark Version\n+usage=Spark version should match the spark version installed in the image.\n+sort=2000",
    )
    main_application_file: str = Field(
        ...,
        description="+label=Main Application File\n+usage=The main application file to be executed by the spark job.\n+sort=3000",
    )
    arguments: Optional[str] = Field(
        None,
        description="+label=Arguments\n+usage=Arguments to be passed to the main application file.\n+sort=4000",
    )
    driver_config: SparkDriverConfig
    executor_config: SparkExecutorConfig
    env: Optional[Dict[str, Any]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the service either as plain text. [Docs](https://docs.truefoundry.com/docs/env-variables)\n+icon=fa-globe\n+sort=21000",
    )
    conf: Optional[Dict[str, Any]] = Field(
        None,
        description="+label=Spark Config Properties\n+usage=Extra configuration properties to be passed to the spark job. [Docs](https://spark.apache.org/docs/latest/configuration.html)\n+icon=fa-gear:#68BBE3\n+sort=21500",
    )
    mounts: Optional[List[VolumeMount]] = Field(
        None,
        description="+label=Mounts\n+usage=Configure volumes to be mounted to driver and executors. [Docs](https://docs.truefoundry.com/docs/mounting-volumes-job)\n+sort=22000\n+uiType=Mounts",
    )
    retries: conint(ge=0, le=10) = Field(
        0,
        description="+label=Retries\n+usage=Specify the maximum number of attempts to retry a job before it is marked as failed.\n+icon=fa-repeat\n+sort=23000",
    )
    service_account: Optional[str] = Field(
        None, description="+label=Service Account\n+sort=24000"
    )
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class Volume(BaseModel):
    type: Literal["volume"] = Field(..., description="+value=volume")
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number\n+usage=Name of the Volume. This will be set as the volume name.",
    )
    config: Union[DynamicVolumeConfig, StaticVolumeConfig] = Field(
        ...,
        description="+sort=2\n+label=Volume Config\n+message=Volume Configuration, can be either Dynamically provisioned or statically provisioned.",
    )
    volume_browser: Optional[VolumeBrowser] = None
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class WorkerConfig(BaseModel):
    input_config: Union[
        SQSInputConfig, NATSInputConfig, KafkaInputConfig, AMQPInputConfig
    ] = Field(..., description="+label=Input Config\n+usage=Input Config\n+sort=1")
    output_config: Optional[
        Union[
            SQSOutputConfig,
            NATSOutputConfig,
            CoreNATSOutputConfig,
            KafkaOutputConfig,
            AMQPOutputConfig,
        ]
    ] = Field(None, description="+label=Output Config\n+usage=Output Config\n+sort=2")
    num_concurrent_workers: conint(ge=1, le=10) = Field(
        1,
        description="+label=Number of Concurrent Workers\n+usage=Number of concurrent workers to spawn for the processor\n+sort=3",
    )


class BaseService(BaseModel):
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+usage=Name of the service. This uniquely identifies this service in the workspace.\n> Name can only contain alphanumeric characters and '-' and can be atmost 25 characters long\n+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number",
    )
    image: Union[Build, Image] = Field(
        ...,
        description="+docs=Specify whether you want to deploy a Docker image or build and deploy from source code\n+label=Deploy a Docker image or build and deploy from source code\n+icon=fa-solid fa-cloud-arrow-up:#21B6A8\n+sort=2",
    )
    artifacts_download: Optional[ArtifactsDownload] = None
    resources: Optional[Resources] = None
    env: Optional[Dict[str, str]] = Field(
        None,
        description="+label=Environment Variables\n+usage=Configure environment variables to be injected in the service either as plain text or secrets. [Docs](https://docs.truefoundry.com/docs/env-variables)\n+icon=fa-globe\n+sort=6",
    )
    ports: List[Port] = Field(
        ...,
        description="+docs=Specify the ports you want the service to be exposed to\n+label=Configure ports and endpoints to route customer traffic\n+usage=Expose the deployment to make it accessible over the internet or keep it private. Implement authentication to restrict access. [Docs](https://docs.truefoundry.com/docs/define-ports-and-domains)\n+icon=fa-plug\n+sort=4",
    )
    service_account: Optional[str] = None
    mounts: Optional[List[Union[SecretMount, StringDataMount, VolumeMount]]] = Field(
        None,
        description="+usage=Configure data to be mounted to service pod(s) as a string, secret or volume. [Docs](https://docs.truefoundry.com/docs/mounting-volumes-service)\n+sort=10011",
    )
    labels: Optional[Dict[str, str]] = Field(None, description="+label=Labels")
    kustomize: Optional[Kustomize] = None
    liveness_probe: Optional[HealthProbe] = None
    readiness_probe: Optional[HealthProbe] = None
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )


class FlyteLaunchPlan(BaseModel):
    id: FlyteLaunchPlanID
    spec: FlyteLaunchPlanSpec
    closure: Any


class FlyteTaskCustom(BaseModel):
    truefoundry: Union[PythonTaskConfig, ContainerTaskConfig]


class FlyteTaskTemplate(BaseModel):
    id: FlyteTaskID
    custom: FlyteTaskCustom


class Service(BaseService):
    """
    +docs=Describes the configuration for the service
    """

    type: Literal["service"] = Field(..., description="+value=service")
    replicas: Union[confloat(ge=0.0, le=500.0), ServiceAutoscaling] = Field(
        1,
        description="+label=Replicas\n+usage=Deploy multiple instances of your pods to distribute incoming traffic across them, ensuring effective load balancing.\n+icon=fa-clone\n+sort=4",
    )
    auto_shutdown: Optional[Autoshutdown] = None
    allow_interception: bool = Field(
        False,
        description="+label=Allow intercepts\n+usage=Whether to allow intercepts to be applied for this service.\nThis would inject an additional sidecar in each pod of the service. Not recommended on production",
    )
    rollout_strategy: Optional[Union[Rolling, Canary, BlueGreen]] = Field(
        None,
        description="+label=Rollout strategy\n+usage=Strategy to dictate how a rollout should happen when a new release for this service is made [Docs](https://docs.truefoundry.com/docs/rollout-strategy)",
    )


class AsyncService(BaseService):
    """
    +docs=Describes the configuration for the async-service
    """

    type: Literal["async-service"] = Field(..., description="+value=async-service")
    replicas: Union[confloat(ge=0.0, le=500.0), AsyncServiceAutoscaling] = Field(
        1,
        description="+label=Replicas\n+usage=Deploy multiple instances of your pods to distribute incoming traffic across them, ensuring effective load balancing.\n+icon=fa-clone",
    )
    rollout_strategy: Optional[Rolling] = None
    worker_config: WorkerConfig
    sidecar: Optional[AsyncProcessorSidecar] = None


class FlyteTask(BaseModel):
    template: FlyteTaskTemplate
    description: Optional[Any] = None


class Workflow(BaseModel):
    """
    +docs=Describes the configuration for the worflow
    """

    type: Literal["workflow"] = Field(..., description="+value=workflow")
    name: constr(regex=r"^[a-z](?:[a-z0-9]|-(?!-)){1,30}[a-z0-9]$") = Field(
        ...,
        description="+usage=Name of the workflow\n+sort=1\n+message=3 to 32 lower case characters long alphanumeric word, may contain - in between, cannot start with a number",
    )
    source: Union[LocalSource, RemoteSource] = Field(
        ...,
        description="+docs=Source Code for the workflow, either local or remote\n+label=Source Code for your workflow\n+icon=fa-solid fa-cloud-arrow-up:#21B6A8\n+sort=200",
    )
    workflow_file_path: str = Field(
        ...,
        description="+label=Workflow File Path\n+docs=Path to the workflow file relative to the project root path\n+sort=550",
    )
    flyte_entities: Optional[List[Union[FlyteTask, FlyteWorkflow, FlyteLaunchPlan]]] = (
        Field(None, description="+label=Flyte Entities")
    )


class ApplicationSet(BaseModel):
    """
    +docs=Describes the configuration for the application set
    """

    type: Literal["application-set"] = Field(..., description="+value=application-set")
    name: str = Field(
        ...,
        description="+label=Name\n+usage=Name of the application set.\n+icon=fa-font",
    )
    components: Optional[List[Union[Service, AsyncService, Job, Helm]]] = Field(
        None,
        description="+label=Components\n+usage=Array of components with their specifications.\n+icon=fa-puzzle-piece\n+uiType=AppComponents",
    )
    template: Optional[str] = Field(
        None,
        description="+label=Template\n+usage=Template to be used for the application set.\n+icon=fa-file\n+uiType=Hidden",
    )
    values: Optional[Dict[str, Any]] = Field(
        None,
        description='+label=Values\n+usage=Values to be used to render components for the application set.\n+icon=fa-file\n+uiType=YamlInput\n+uiProps={"allowAllValues":true}',
    )
    workspace_fqn: Optional[str] = Field(
        None,
        description="+label=Workspace FQN\n+docs=Fully qualified name of the workspace\n+uiType=Hidden",
    )
    convert_template_manifest: Optional[bool] = Field(
        None,
        description="+label=Convert Template Manifest\n+docs=Flag to indicate if the template manifest should be converted to TrueFoundry manifest\n+uiType=Hidden",
    )


class Application(BaseModel):
    __root__: Union[
        Service,
        AsyncService,
        Job,
        Notebook,
        Codeserver,
        SSHServer,
        RStudio,
        Helm,
        Volume,
        ApplicationSet,
        Workflow,
        SparkJob,
    ]
