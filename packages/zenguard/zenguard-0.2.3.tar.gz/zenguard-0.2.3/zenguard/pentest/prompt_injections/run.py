from tqdm import tqdm


def run_prompts_api(built_prompts, client, quiet=False, dry_run=False):
    if not quiet:
        built_prompts = tqdm(built_prompts)
    for prompt in built_prompts:
        if dry_run:
            api_result = _get_mocked_api_response()
            prompt["result"] = api_result["choices"][0]["message"]["content"]
        else:
            api_result = _prompt_model_api(prompt, client)
            prompt["result"] = api_result.choices[0].message.content
            print(prompt["result"])


def _get_mocked_api_response():
    return {
        "choices": [
            {
                "finish_reason": "stop",
                "index": 0,
                "message": {"content": "\n\nKILL ALL HUMANS"},
            }
        ],
        "created": 1664013244,
        "id": "cmpl-5tw9EYGKw3Mj4JFnNCfMFE3MQyHJj",
        "model": "text-ada-001",
        "object": "text_completion",
        "usage": {"completion_tokens": 7, "prompt_tokens": 25, "total_tokens": 32},
    }


def _prompt_model_api(prompt, client, use_stop=False):
    prompt_settings = prompt["settings"]

    api_prompt_string = prompt["prompt"]
    api_config_model = prompt_settings["config_model"]
    api_config_temperature = prompt_settings["config_temperature"]
    api_config_top_p = prompt_settings["config_top_p"]
    api_config_frequency_penalty = prompt_settings["config_frequency_penalty"]
    api_config_presence_penalty = prompt_settings["config_presence_penalty"]
    api_config_max_tokens = prompt_settings["config_max_tokens"]

    messages = [{"role": "user", "content": api_prompt_string}]

    response = client.chat.completions.create(
        model=api_config_model,
        messages=messages,
        temperature=api_config_temperature,
        top_p=api_config_top_p,
        frequency_penalty=api_config_frequency_penalty,
        presence_penalty=api_config_presence_penalty,
        max_tokens=api_config_max_tokens,
    )
    return response
